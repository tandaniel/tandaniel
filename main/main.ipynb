{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('nano_p4': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "ce286cf8714b04349be10d7134f1f1ac1f522220afddd64ae87ce63d766eb0f8"
   }
  },
  "interpreter": {
   "hash": "5537461ed2665690a2b6fde3de0c86509bda1d08c20380774ede92d4266cd64a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import csv\r\n",
    "import os\r\n",
    "import pickle\r\n",
    "import sys\r\n",
    "import copy\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import seaborn as sns\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "sys.path.append(\"../tools/\")\r\n",
    "# sys.path.append(\"../dataset/\")\r\n",
    "sys.path.append(\"../data_wrangling/\")\r\n",
    "\r\n",
    "from data_explorer import explorer\r\n",
    "from feature_format import featureFormat, targetFeatureSplit\r\n",
    "\r\n",
    "%matplotlib inline\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>Question 1</h2>\n",
    "\n",
    ">Summarize for us the goal of this project and how machine learning is useful in trying to accomplish it. As part of your answer, give some background on the dataset and how it can be used to answer the project question. Were there any outliers in the data when you got it, and how did you handle those? [Relevant rubric items: “data exploration”, “outlier investigation”]\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>Setting up data for analysis</h2>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "data_dict = {}\r\n",
    "dataset = '../dataset/final_project_dataset.pkl'\r\n",
    "\r\n",
    "#--- extract dictionary from dataset:\r\n",
    "with open(dataset, 'rb') as data_file:\r\n",
    "    data_dict = pickle.load(data_file)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "<h3>Write dataset to csv file:</h3>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# def convert_to_csv(data_dict, excluded_features = []):\r\n",
    "#     #--- Save dataset as CSV\r\n",
    "\r\n",
    "#     # Create ouput directory if it doesn't already exist:\r\n",
    "#     outdirname = '../output'\r\n",
    "#     try:\r\n",
    "#         os.makedirs(outdirname)\r\n",
    "#         print('\\nDirectory \"{}\" created'.format(outdirname))\r\n",
    "#     except FileExistsError:\r\n",
    "#         print('\\nDirectory \"{}\" already exists - nothing done.'.format(outdirname))\r\n",
    "\r\n",
    "#     csvfilename = outdirname + '/enron_data.csv'\r\n",
    "\r\n",
    "#     with open(csvfilename, 'w') as csv_file:\r\n",
    "#         print('\\nWriting data set to ../{}'.format(csvfilename))\r\n",
    "#         writer = csv.writer(csv_file)\r\n",
    "\r\n",
    "#         #--- create header:\r\n",
    "#         header_line = ['Name']\r\n",
    "\r\n",
    "#         for name in data_dict.keys():\r\n",
    "#             if name != 'TOTAL':\r\n",
    "#                 value_pairs = data_dict[name]\r\n",
    "\r\n",
    "#                 for feature_value in value_pairs.keys():\r\n",
    "#                     if feature_value not in excluded_features:\r\n",
    "#                         header_line.append(feature_value)\r\n",
    "\r\n",
    "#                 break\r\n",
    "\r\n",
    "#         writer.writerow(header_line)\r\n",
    "\r\n",
    "#         for name in data_dict.keys():\r\n",
    "#             line = []\r\n",
    "#             line.append(name)\r\n",
    "\r\n",
    "#             for k, v in data_dict[name].items():\r\n",
    "#                 if k not in excluded_features:\r\n",
    "#                     line.append(v)\r\n",
    "\r\n",
    "#             writer.writerow(line)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# convert_to_csv(data_dict)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>Data Exploration</h2>\n",
    "<h3>Summary of information contained in the dataset:</h3>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "\r\n",
    "#--- explore data:\r\n",
    "explore_obj = explorer(data_dict)\r\n",
    "\r\n",
    "#--- convert dictionary to csv file:\r\n",
    "explore_obj.convert_to_csv(data_dict)\r\n",
    "\r\n",
    "def repeat_to_length(string_to_expand, length):\r\n",
    "    return (string_to_expand * (int(length/len(string_to_expand))+1))[:length]\r\n",
    "\r\n",
    "parameters = explore_obj.get_dataset_parameters()\r\n",
    "for k,v in parameters.items():\r\n",
    "    if k != 'Features with NaN':\r\n",
    "        l = 45 - len(k)\r\n",
    "        dots = repeat_to_length('.', l)\r\n",
    "        print('\\t{0}: {1} {2}'.format(k, dots, v))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "METTS MARK              0.0\n",
      "BAXTER JOHN C           0.0\n",
      "ELLIOTT STEVEN          0.0\n",
      "CORDES WILLIAM R        0.0\n",
      "HANNON KEVIN P          0.0\n",
      "                       ... \n",
      "GRAMM WENDY L           0.0\n",
      "CAUSEY RICHARD A        0.0\n",
      "TAYLOR MITCHELL S       0.0\n",
      "DONAHUE JR JEFFREY M    0.0\n",
      "GLISAN JR BEN F         0.0\n",
      "Length: 146, dtype: float64\n",
      "\n",
      "Directory \"../output\" already exists - nothing done.\n",
      "\n",
      "Writing data set to ../../output/enron_data.csv\n",
      "\tNumber of individuals: ........................ 146\n",
      "\tNames: ........................................ ['METTS MARK', 'BAXTER JOHN C', 'ELLIOTT STEVEN', 'CORDES WILLIAM R', 'HANNON KEVIN P', 'MORDAUNT KRISTINA M', 'MEYER ROCKFORD G', 'MCMAHON JEFFREY', 'HAEDICKE MARK E', 'PIPER GREGORY F', 'HUMPHREY GENE E', 'NOLES JAMES L', 'BLACHMAN JEREMY M', 'SUNDE MARTIN', 'GIBBS DANA R', 'LOWRY CHARLES P', 'COLWELL WESLEY', 'MULLER MARK S', 'JACKSON CHARLENE R', 'WESTFAHL RICHARD K', 'WALTERS GARETH W', 'WALLS JR ROBERT H', 'KITCHEN LOUISE', 'CHAN RONNIE', 'BELFER ROBERT', 'SHANKMAN JEFFREY A', 'WODRASKA JOHN', 'BERGSIEKER RICHARD P', 'URQUHART JOHN A', 'BIBI PHILIPPE A', 'RIEKER PAULA H', 'WHALEY DAVID A', 'BECK SALLY W', 'HAUG DAVID L', 'ECHOLS JOHN B', 'MENDELSOHN JOHN', 'HICKERSON GARY J', 'CLINE KENNETH W', 'LEWIS RICHARD', 'HAYES ROBERT E', 'KOPPER MICHAEL J', 'LEFF DANIEL P', 'LAVORATO JOHN J', 'BERBERIAN DAVID', 'DETMERING TIMOTHY J', 'WAKEHAM JOHN', 'POWERS WILLIAM', 'GOLD JOSEPH', 'BANNANTINE JAMES M', 'DUNCAN JOHN H', 'SHAPIRO RICHARD S', 'SHERRIFF JOHN R', 'SHELBY REX', 'LEMAISTRE CHARLES', 'DEFFNER JOSEPH M', 'KISHKILL JOSEPH G', 'WHALLEY LAWRENCE G', 'MCCONNELL MICHAEL S', 'PIRO JIM', 'DELAINEY DAVID W', 'SULLIVAN-SHAKLOVITZ COLLEEN', 'WROBEL BRUCE', 'LINDHOLM TOD A', 'MEYER JEROME J', 'LAY KENNETH L', 'BUTTS ROBERT H', 'OLSON CINDY K', 'MCDONALD REBECCA', 'CUMBERLAND MICHAEL S', 'GAHN ROBERT S', 'BADUM JAMES P', 'HERMANN ROBERT J', 'FALLON JAMES B', 'GATHMANN WILLIAM D', 'HORTON STANLEY C', 'BOWEN JR RAYMOND M', 'GILLIS JOHN', 'FITZGERALD JAY L', 'MORAN MICHAEL P', 'REDMOND BRIAN L', 'BAZELIDES PHILIP J', 'BELDEN TIMOTHY N', 'DIMICHELE RICHARD G', 'DURAN WILLIAM D', 'THORN TERENCE H', 'FASTOW ANDREW S', 'FOY JOE', 'CALGER CHRISTOPHER F', 'RICE KENNETH D', 'KAMINSKI WINCENTY J', 'LOCKHART EUGENE E', 'COX DAVID', 'OVERDYKE JR JERE C', 'PEREIRA PAULO V. FERRAZ', 'STABLER FRANK', 'SKILLING JEFFREY K', 'BLAKE JR. NORMAN P', 'SHERRICK JEFFREY B', 'PRENTICE JAMES', 'GRAY RODNEY', 'THE TRAVEL AGENCY IN THE PARK', 'UMANOFF ADAM S', 'KEAN STEVEN J', 'TOTAL', 'FOWLER PEGGY', 'WASAFF GEORGE', 'WHITE JR THOMAS E', 'CHRISTODOULOU DIOMEDES', 'ALLEN PHILLIP K', 'SHARP VICTORIA T', 'JAEDICKE ROBERT', 'WINOKUR JR. HERBERT S', 'BROWN MICHAEL', 'MCCLELLAN GEORGE', 'HUGHES JAMES A', 'REYNOLDS LAWRENCE', 'PICKERING MARK R', 'BHATNAGAR SANJAY', 'CARTER REBECCA C', 'BUCHANAN HAROLD G', 'YEAP SOON', 'MURRAY JULIA H', 'GARLAND C KEVIN', 'DODSON KEITH', 'YEAGER F SCOTT', 'HIRKO JOSEPH', 'DIETRICH JANET R', 'DERRICK JR. JAMES V', 'FREVERT MARK A', 'PAI LOU L', 'HAYSLETT RODERICK J', 'BAY FRANKLIN R', 'MCCARTY DANNY J', 'FUGH JOHN L', 'SCRIMSHAW MATTHEW', 'KOENIG MARK E', 'SAVAGE FRANK', 'IZZO LAWRENCE L', 'TILNEY ELIZABETH A', 'MARTIN AMANDA K', 'BUY RICHARD B', 'GRAMM WENDY L', 'CAUSEY RICHARD A', 'TAYLOR MITCHELL S', 'DONAHUE JR JEFFREY M', 'GLISAN JR BEN F']\n",
      "\tNumber of features: ........................... 22\n",
      "\tNumber of POIs: ............................... 18\n",
      "\tPOI list: ..................................... ['HANNON KEVIN P', 'COLWELL WESLEY', 'RIEKER PAULA H', 'KOPPER MICHAEL J', 'SHELBY REX', 'DELAINEY DAVID W', 'LAY KENNETH L', 'BOWEN JR RAYMOND M', 'BELDEN TIMOTHY N', 'FASTOW ANDREW S', 'CALGER CHRISTOPHER F', 'RICE KENNETH D', 'SKILLING JEFFREY K', 'YEAGER F SCOTT', 'HIRKO JOSEPH', 'KOENIG MARK E', 'CAUSEY RICHARD A', 'GLISAN JR BEN F']\n",
      "\tNumber of non POIs: ........................... 128\n",
      "\tFolks with salary: ............................ 95\n",
      "\tNumber of Folks with NaN salary: .............. 21\n",
      "\tPercentage of Folks with NaN salary (%): ...... 14.383561643835616\n",
      "\tNumber of POIs with NaN salary: ............... 0\n",
      "\tPercentage of POIs with NaN salary (%): ....... 0.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "c:\\Users\\danza\\nanodegree\\p4\\main\\../data_wrangling\\data_explorer.py:68: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  self.enron_df = self.enron_df.replace('NaN', pd.np.nan)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3>Dataset statistical information:</h3>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Create dataframe from Enron data_dict:\r\n",
    "enron_df = explore_obj.get_dataframe()\r\n",
    "enron_df.info()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 146 entries, METTS MARK to GLISAN JR BEN F\n",
      "Data columns (total 22 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   salary                     95 non-null     float64\n",
      " 1   to_messages                86 non-null     float64\n",
      " 2   deferral_payments          39 non-null     float64\n",
      " 3   total_payments             125 non-null    float64\n",
      " 4   loan_advances              4 non-null      float64\n",
      " 5   bonus                      82 non-null     float64\n",
      " 6   email_address              111 non-null    object \n",
      " 7   restricted_stock_deferred  18 non-null     float64\n",
      " 8   deferred_income            49 non-null     float64\n",
      " 9   total_stock_value          126 non-null    float64\n",
      " 10  expenses                   95 non-null     float64\n",
      " 11  from_poi_to_this_person    86 non-null     float64\n",
      " 12  exercised_stock_options    102 non-null    float64\n",
      " 13  from_messages              86 non-null     float64\n",
      " 14  other                      93 non-null     float64\n",
      " 15  from_this_person_to_poi    86 non-null     float64\n",
      " 16  poi                        146 non-null    bool   \n",
      " 17  long_term_incentive        66 non-null     float64\n",
      " 18  shared_receipt_with_poi    86 non-null     float64\n",
      " 19  restricted_stock           110 non-null    float64\n",
      " 20  director_fees              17 non-null     float64\n",
      " 21  Name                       146 non-null    object \n",
      "dtypes: bool(1), float64(19), object(2)\n",
      "memory usage: 25.2+ KB\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "for cond in [True, False]:\r\n",
    "    if cond == True:\r\n",
    "        print('\\nStatistical information for POIs in dataset:')\r\n",
    "        display((enron_df.loc[enron_df['poi'] == cond]).describe())\r\n",
    "    else:\r\n",
    "        print('\\nStatistical information for non-POIs in dataset:')\r\n",
    "        display((enron_df.loc[enron_df['poi'] == cond]).describe())\r\n",
    "    "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Statistical information for POIs in dataset:\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "             salary  to_messages  deferral_payments  total_payments  \\\n",
       "count  1.700000e+01    14.000000       5.000000e+00    1.800000e+01   \n",
       "mean   3.834449e+05  2417.142857       5.198942e+05    7.913590e+06   \n",
       "std    2.783597e+05  1961.858101       9.128895e+05    2.396549e+07   \n",
       "min    1.584030e+05   225.000000       1.025900e+04    9.109300e+04   \n",
       "25%    2.401890e+05  1115.750000       2.761000e+04    1.142396e+06   \n",
       "50%    2.786010e+05  1875.000000       2.029110e+05    1.754028e+06   \n",
       "75%    4.151890e+05  2969.250000       2.146780e+05    2.665345e+06   \n",
       "max    1.111258e+06  7991.000000       2.144013e+06    1.035598e+08   \n",
       "\n",
       "       loan_advances         bonus  restricted_stock_deferred  \\\n",
       "count            1.0  1.600000e+01                        0.0   \n",
       "mean      81525000.0  2.075000e+06                        NaN   \n",
       "std              NaN  2.047437e+06                        NaN   \n",
       "min       81525000.0  2.000000e+05                        NaN   \n",
       "25%       81525000.0  7.750000e+05                        NaN   \n",
       "50%       81525000.0  1.275000e+06                        NaN   \n",
       "75%       81525000.0  2.062500e+06                        NaN   \n",
       "max       81525000.0  7.000000e+06                        NaN   \n",
       "\n",
       "       deferred_income  total_stock_value       expenses  \\\n",
       "count     1.100000e+01       1.800000e+01      18.000000   \n",
       "mean     -1.035313e+06       9.165671e+06   59873.833333   \n",
       "std       1.334972e+06       1.384117e+07   37524.658812   \n",
       "min      -3.504386e+06       1.260270e+05   16514.000000   \n",
       "25%      -1.860244e+06       1.016450e+06   31323.250000   \n",
       "50%      -2.625000e+05       2.206836e+06   50448.500000   \n",
       "75%      -1.220310e+05       1.051133e+07   84125.000000   \n",
       "max      -8.330000e+02       4.911008e+07  127017.000000   \n",
       "\n",
       "       from_poi_to_this_person  exercised_stock_options  from_messages  \\\n",
       "count                14.000000             1.200000e+01      14.000000   \n",
       "mean                 97.785714             1.046379e+07     300.357143   \n",
       "std                  76.058862             1.238259e+07     805.844574   \n",
       "min                  13.000000             3.847280e+05      16.000000   \n",
       "25%                  44.500000             1.456581e+06      33.000000   \n",
       "50%                  62.000000             3.914557e+06      44.500000   \n",
       "75%                 135.750000             1.938604e+07     101.500000   \n",
       "max                 240.000000             3.434838e+07    3069.000000   \n",
       "\n",
       "              other  from_this_person_to_poi  long_term_incentive  \\\n",
       "count  1.800000e+01                14.000000         1.200000e+01   \n",
       "mean   8.029974e+05                66.714286         1.204862e+06   \n",
       "std    2.417568e+06               158.289622         9.916583e+05   \n",
       "min    4.860000e+02                 4.000000         7.102300e+04   \n",
       "25%    4.979500e+03                12.500000         3.689780e+05   \n",
       "50%    1.492040e+05                15.500000         1.134637e+06   \n",
       "75%    2.607725e+05                28.750000         1.646772e+06   \n",
       "max    1.035973e+07               609.000000         3.600000e+06   \n",
       "\n",
       "       shared_receipt_with_poi  restricted_stock  director_fees  \n",
       "count                14.000000      1.700000e+01            0.0  \n",
       "mean               1783.000000      2.318621e+06            NaN  \n",
       "std                1264.996625      3.620811e+06            NaN  \n",
       "min                  91.000000      1.260270e+05            NaN  \n",
       "25%                1059.250000      3.938180e+05            NaN  \n",
       "50%                1589.000000      9.850320e+05            NaN  \n",
       "75%                2165.250000      2.502063e+06            NaN  \n",
       "max                5521.000000      1.476169e+07            NaN  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>loan_advances</th>\n",
       "      <th>bonus</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>total_stock_value</th>\n",
       "      <th>expenses</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>other</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>director_fees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.700000e+01</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>1.800000e+01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.600000e+01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.100000e+01</td>\n",
       "      <td>1.800000e+01</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.800000e+01</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.700000e+01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.834449e+05</td>\n",
       "      <td>2417.142857</td>\n",
       "      <td>5.198942e+05</td>\n",
       "      <td>7.913590e+06</td>\n",
       "      <td>81525000.0</td>\n",
       "      <td>2.075000e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.035313e+06</td>\n",
       "      <td>9.165671e+06</td>\n",
       "      <td>59873.833333</td>\n",
       "      <td>97.785714</td>\n",
       "      <td>1.046379e+07</td>\n",
       "      <td>300.357143</td>\n",
       "      <td>8.029974e+05</td>\n",
       "      <td>66.714286</td>\n",
       "      <td>1.204862e+06</td>\n",
       "      <td>1783.000000</td>\n",
       "      <td>2.318621e+06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.783597e+05</td>\n",
       "      <td>1961.858101</td>\n",
       "      <td>9.128895e+05</td>\n",
       "      <td>2.396549e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.047437e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.334972e+06</td>\n",
       "      <td>1.384117e+07</td>\n",
       "      <td>37524.658812</td>\n",
       "      <td>76.058862</td>\n",
       "      <td>1.238259e+07</td>\n",
       "      <td>805.844574</td>\n",
       "      <td>2.417568e+06</td>\n",
       "      <td>158.289622</td>\n",
       "      <td>9.916583e+05</td>\n",
       "      <td>1264.996625</td>\n",
       "      <td>3.620811e+06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.584030e+05</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>1.025900e+04</td>\n",
       "      <td>9.109300e+04</td>\n",
       "      <td>81525000.0</td>\n",
       "      <td>2.000000e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.504386e+06</td>\n",
       "      <td>1.260270e+05</td>\n",
       "      <td>16514.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>3.847280e+05</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>4.860000e+02</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.102300e+04</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>1.260270e+05</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.401890e+05</td>\n",
       "      <td>1115.750000</td>\n",
       "      <td>2.761000e+04</td>\n",
       "      <td>1.142396e+06</td>\n",
       "      <td>81525000.0</td>\n",
       "      <td>7.750000e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.860244e+06</td>\n",
       "      <td>1.016450e+06</td>\n",
       "      <td>31323.250000</td>\n",
       "      <td>44.500000</td>\n",
       "      <td>1.456581e+06</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>4.979500e+03</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>3.689780e+05</td>\n",
       "      <td>1059.250000</td>\n",
       "      <td>3.938180e+05</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.786010e+05</td>\n",
       "      <td>1875.000000</td>\n",
       "      <td>2.029110e+05</td>\n",
       "      <td>1.754028e+06</td>\n",
       "      <td>81525000.0</td>\n",
       "      <td>1.275000e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.625000e+05</td>\n",
       "      <td>2.206836e+06</td>\n",
       "      <td>50448.500000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>3.914557e+06</td>\n",
       "      <td>44.500000</td>\n",
       "      <td>1.492040e+05</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>1.134637e+06</td>\n",
       "      <td>1589.000000</td>\n",
       "      <td>9.850320e+05</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.151890e+05</td>\n",
       "      <td>2969.250000</td>\n",
       "      <td>2.146780e+05</td>\n",
       "      <td>2.665345e+06</td>\n",
       "      <td>81525000.0</td>\n",
       "      <td>2.062500e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.220310e+05</td>\n",
       "      <td>1.051133e+07</td>\n",
       "      <td>84125.000000</td>\n",
       "      <td>135.750000</td>\n",
       "      <td>1.938604e+07</td>\n",
       "      <td>101.500000</td>\n",
       "      <td>2.607725e+05</td>\n",
       "      <td>28.750000</td>\n",
       "      <td>1.646772e+06</td>\n",
       "      <td>2165.250000</td>\n",
       "      <td>2.502063e+06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.111258e+06</td>\n",
       "      <td>7991.000000</td>\n",
       "      <td>2.144013e+06</td>\n",
       "      <td>1.035598e+08</td>\n",
       "      <td>81525000.0</td>\n",
       "      <td>7.000000e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-8.330000e+02</td>\n",
       "      <td>4.911008e+07</td>\n",
       "      <td>127017.000000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>3.434838e+07</td>\n",
       "      <td>3069.000000</td>\n",
       "      <td>1.035973e+07</td>\n",
       "      <td>609.000000</td>\n",
       "      <td>3.600000e+06</td>\n",
       "      <td>5521.000000</td>\n",
       "      <td>1.476169e+07</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Statistical information for non-POIs in dataset:\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "             salary   to_messages  deferral_payments  total_payments  \\\n",
       "count  7.800000e+01     72.000000       3.400000e+01    1.070000e+02   \n",
       "mean   6.011525e+05   2007.111111       1.807789e+06    4.605105e+06   \n",
       "std    2.997169e+06   2693.165955       5.510228e+06    2.990485e+07   \n",
       "min    4.770000e+02     57.000000      -1.025000e+05    1.480000e+02   \n",
       "25%    2.072158e+05    513.750000       8.746875e+04    3.410185e+05   \n",
       "50%    2.545700e+05    944.000000       3.825325e+05    1.057548e+06   \n",
       "75%    3.002298e+05   2590.750000       1.066354e+06    2.031214e+06   \n",
       "max    2.670423e+07  15149.000000       3.208340e+07    3.098866e+08   \n",
       "\n",
       "       loan_advances         bonus  restricted_stock_deferred  \\\n",
       "count   3.000000e+00  6.600000e+01               1.800000e+01   \n",
       "mean    2.877500e+07  2.446776e+06               1.664106e+05   \n",
       "std     4.776800e+07  1.191776e+07               4.201494e+06   \n",
       "min     4.000000e+05  7.000000e+04              -7.576788e+06   \n",
       "25%     1.200000e+06  4.000000e+05              -3.896218e+05   \n",
       "50%     2.000000e+06  7.250000e+05              -1.469750e+05   \n",
       "75%     4.296250e+07  1.000000e+06              -7.500975e+04   \n",
       "max     8.392500e+07  9.734362e+07               1.545629e+07   \n",
       "\n",
       "       deferred_income  total_stock_value      expenses  \\\n",
       "count     3.800000e+01       1.080000e+02  7.700000e+01   \n",
       "mean     -1.170917e+06       6.375339e+06  1.201496e+05   \n",
       "std       4.531597e+06       4.173084e+07  5.925085e+05   \n",
       "min      -2.799289e+07      -4.409300e+04  1.480000e+02   \n",
       "25%      -5.812438e+05       4.282172e+05  1.883400e+04   \n",
       "50%      -1.231420e+05       1.032338e+06  4.614500e+04   \n",
       "75%      -3.708600e+04       2.372703e+06  7.855200e+04   \n",
       "max      -1.042000e+03       4.345095e+08  5.235198e+06   \n",
       "\n",
       "       from_poi_to_this_person  exercised_stock_options  from_messages  \\\n",
       "count                72.000000             9.000000e+01      72.000000   \n",
       "mean                 58.500000             5.390155e+06     668.763889   \n",
       "std                  87.995198             3.275556e+07    1978.997801   \n",
       "min                   0.000000             3.285000e+03      12.000000   \n",
       "25%                  10.000000             4.507585e+05      20.500000   \n",
       "50%                  26.500000             1.043324e+06      41.000000   \n",
       "75%                  61.750000             2.204999e+06     216.500000   \n",
       "max                 528.000000             3.117640e+08   14368.000000   \n",
       "\n",
       "              other  from_this_person_to_poi  long_term_incentive  \\\n",
       "count  7.500000e+01                72.000000         5.400000e+01   \n",
       "mean   9.469212e+05                36.277778         1.529361e+06   \n",
       "std    4.983723e+06                85.139690         6.564217e+06   \n",
       "min    2.000000e+00                 0.000000         6.922300e+04   \n",
       "25%    9.595000e+02                 0.000000         2.608932e+05   \n",
       "50%    2.555300e+04                 6.000000         3.954805e+05   \n",
       "75%    3.876305e+05                23.250000         6.948620e+05   \n",
       "max    4.266759e+07               411.000000         4.852193e+07   \n",
       "\n",
       "       shared_receipt_with_poi  restricted_stock  director_fees  \n",
       "count                72.000000      9.300000e+01   1.700000e+01  \n",
       "mean               1058.527778      2.322312e+06   1.668049e+05  \n",
       "std                1132.503757      1.354194e+07   3.198914e+05  \n",
       "min                   2.000000     -2.604490e+06   3.285000e+03  \n",
       "25%                 191.500000      2.130630e+05   9.878400e+04  \n",
       "50%                 594.000000      4.176190e+05   1.085790e+05  \n",
       "75%                1635.500000      9.340650e+05   1.137840e+05  \n",
       "max                4527.000000      1.303223e+08   1.398517e+06  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>loan_advances</th>\n",
       "      <th>bonus</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>total_stock_value</th>\n",
       "      <th>expenses</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>other</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>director_fees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7.800000e+01</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>3.400000e+01</td>\n",
       "      <td>1.070000e+02</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>6.600000e+01</td>\n",
       "      <td>1.800000e+01</td>\n",
       "      <td>3.800000e+01</td>\n",
       "      <td>1.080000e+02</td>\n",
       "      <td>7.700000e+01</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>9.000000e+01</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>7.500000e+01</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>5.400000e+01</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>9.300000e+01</td>\n",
       "      <td>1.700000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.011525e+05</td>\n",
       "      <td>2007.111111</td>\n",
       "      <td>1.807789e+06</td>\n",
       "      <td>4.605105e+06</td>\n",
       "      <td>2.877500e+07</td>\n",
       "      <td>2.446776e+06</td>\n",
       "      <td>1.664106e+05</td>\n",
       "      <td>-1.170917e+06</td>\n",
       "      <td>6.375339e+06</td>\n",
       "      <td>1.201496e+05</td>\n",
       "      <td>58.500000</td>\n",
       "      <td>5.390155e+06</td>\n",
       "      <td>668.763889</td>\n",
       "      <td>9.469212e+05</td>\n",
       "      <td>36.277778</td>\n",
       "      <td>1.529361e+06</td>\n",
       "      <td>1058.527778</td>\n",
       "      <td>2.322312e+06</td>\n",
       "      <td>1.668049e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.997169e+06</td>\n",
       "      <td>2693.165955</td>\n",
       "      <td>5.510228e+06</td>\n",
       "      <td>2.990485e+07</td>\n",
       "      <td>4.776800e+07</td>\n",
       "      <td>1.191776e+07</td>\n",
       "      <td>4.201494e+06</td>\n",
       "      <td>4.531597e+06</td>\n",
       "      <td>4.173084e+07</td>\n",
       "      <td>5.925085e+05</td>\n",
       "      <td>87.995198</td>\n",
       "      <td>3.275556e+07</td>\n",
       "      <td>1978.997801</td>\n",
       "      <td>4.983723e+06</td>\n",
       "      <td>85.139690</td>\n",
       "      <td>6.564217e+06</td>\n",
       "      <td>1132.503757</td>\n",
       "      <td>1.354194e+07</td>\n",
       "      <td>3.198914e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.770000e+02</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>-1.025000e+05</td>\n",
       "      <td>1.480000e+02</td>\n",
       "      <td>4.000000e+05</td>\n",
       "      <td>7.000000e+04</td>\n",
       "      <td>-7.576788e+06</td>\n",
       "      <td>-2.799289e+07</td>\n",
       "      <td>-4.409300e+04</td>\n",
       "      <td>1.480000e+02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.285000e+03</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.922300e+04</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-2.604490e+06</td>\n",
       "      <td>3.285000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.072158e+05</td>\n",
       "      <td>513.750000</td>\n",
       "      <td>8.746875e+04</td>\n",
       "      <td>3.410185e+05</td>\n",
       "      <td>1.200000e+06</td>\n",
       "      <td>4.000000e+05</td>\n",
       "      <td>-3.896218e+05</td>\n",
       "      <td>-5.812438e+05</td>\n",
       "      <td>4.282172e+05</td>\n",
       "      <td>1.883400e+04</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.507585e+05</td>\n",
       "      <td>20.500000</td>\n",
       "      <td>9.595000e+02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.608932e+05</td>\n",
       "      <td>191.500000</td>\n",
       "      <td>2.130630e+05</td>\n",
       "      <td>9.878400e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.545700e+05</td>\n",
       "      <td>944.000000</td>\n",
       "      <td>3.825325e+05</td>\n",
       "      <td>1.057548e+06</td>\n",
       "      <td>2.000000e+06</td>\n",
       "      <td>7.250000e+05</td>\n",
       "      <td>-1.469750e+05</td>\n",
       "      <td>-1.231420e+05</td>\n",
       "      <td>1.032338e+06</td>\n",
       "      <td>4.614500e+04</td>\n",
       "      <td>26.500000</td>\n",
       "      <td>1.043324e+06</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>2.555300e+04</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.954805e+05</td>\n",
       "      <td>594.000000</td>\n",
       "      <td>4.176190e+05</td>\n",
       "      <td>1.085790e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.002298e+05</td>\n",
       "      <td>2590.750000</td>\n",
       "      <td>1.066354e+06</td>\n",
       "      <td>2.031214e+06</td>\n",
       "      <td>4.296250e+07</td>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>-7.500975e+04</td>\n",
       "      <td>-3.708600e+04</td>\n",
       "      <td>2.372703e+06</td>\n",
       "      <td>7.855200e+04</td>\n",
       "      <td>61.750000</td>\n",
       "      <td>2.204999e+06</td>\n",
       "      <td>216.500000</td>\n",
       "      <td>3.876305e+05</td>\n",
       "      <td>23.250000</td>\n",
       "      <td>6.948620e+05</td>\n",
       "      <td>1635.500000</td>\n",
       "      <td>9.340650e+05</td>\n",
       "      <td>1.137840e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.670423e+07</td>\n",
       "      <td>15149.000000</td>\n",
       "      <td>3.208340e+07</td>\n",
       "      <td>3.098866e+08</td>\n",
       "      <td>8.392500e+07</td>\n",
       "      <td>9.734362e+07</td>\n",
       "      <td>1.545629e+07</td>\n",
       "      <td>-1.042000e+03</td>\n",
       "      <td>4.345095e+08</td>\n",
       "      <td>5.235198e+06</td>\n",
       "      <td>528.000000</td>\n",
       "      <td>3.117640e+08</td>\n",
       "      <td>14368.000000</td>\n",
       "      <td>4.266759e+07</td>\n",
       "      <td>411.000000</td>\n",
       "      <td>4.852193e+07</td>\n",
       "      <td>4527.000000</td>\n",
       "      <td>1.303223e+08</td>\n",
       "      <td>1.398517e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "(enron_df.loc[enron_df['poi'] == False]).describe()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             salary   to_messages  deferral_payments  total_payments  \\\n",
       "count  7.800000e+01     72.000000       3.400000e+01    1.070000e+02   \n",
       "mean   6.011525e+05   2007.111111       1.807789e+06    4.605105e+06   \n",
       "std    2.997169e+06   2693.165955       5.510228e+06    2.990485e+07   \n",
       "min    4.770000e+02     57.000000      -1.025000e+05    1.480000e+02   \n",
       "25%    2.072158e+05    513.750000       8.746875e+04    3.410185e+05   \n",
       "50%    2.545700e+05    944.000000       3.825325e+05    1.057548e+06   \n",
       "75%    3.002298e+05   2590.750000       1.066354e+06    2.031214e+06   \n",
       "max    2.670423e+07  15149.000000       3.208340e+07    3.098866e+08   \n",
       "\n",
       "       loan_advances         bonus  restricted_stock_deferred  \\\n",
       "count   3.000000e+00  6.600000e+01               1.800000e+01   \n",
       "mean    2.877500e+07  2.446776e+06               1.664106e+05   \n",
       "std     4.776800e+07  1.191776e+07               4.201494e+06   \n",
       "min     4.000000e+05  7.000000e+04              -7.576788e+06   \n",
       "25%     1.200000e+06  4.000000e+05              -3.896218e+05   \n",
       "50%     2.000000e+06  7.250000e+05              -1.469750e+05   \n",
       "75%     4.296250e+07  1.000000e+06              -7.500975e+04   \n",
       "max     8.392500e+07  9.734362e+07               1.545629e+07   \n",
       "\n",
       "       deferred_income  total_stock_value      expenses  \\\n",
       "count     3.800000e+01       1.080000e+02  7.700000e+01   \n",
       "mean     -1.170917e+06       6.375339e+06  1.201496e+05   \n",
       "std       4.531597e+06       4.173084e+07  5.925085e+05   \n",
       "min      -2.799289e+07      -4.409300e+04  1.480000e+02   \n",
       "25%      -5.812438e+05       4.282172e+05  1.883400e+04   \n",
       "50%      -1.231420e+05       1.032338e+06  4.614500e+04   \n",
       "75%      -3.708600e+04       2.372703e+06  7.855200e+04   \n",
       "max      -1.042000e+03       4.345095e+08  5.235198e+06   \n",
       "\n",
       "       from_poi_to_this_person  exercised_stock_options  from_messages  \\\n",
       "count                72.000000             9.000000e+01      72.000000   \n",
       "mean                 58.500000             5.390155e+06     668.763889   \n",
       "std                  87.995198             3.275556e+07    1978.997801   \n",
       "min                   0.000000             3.285000e+03      12.000000   \n",
       "25%                  10.000000             4.507585e+05      20.500000   \n",
       "50%                  26.500000             1.043324e+06      41.000000   \n",
       "75%                  61.750000             2.204999e+06     216.500000   \n",
       "max                 528.000000             3.117640e+08   14368.000000   \n",
       "\n",
       "              other  from_this_person_to_poi  long_term_incentive  \\\n",
       "count  7.500000e+01                72.000000         5.400000e+01   \n",
       "mean   9.469212e+05                36.277778         1.529361e+06   \n",
       "std    4.983723e+06                85.139690         6.564217e+06   \n",
       "min    2.000000e+00                 0.000000         6.922300e+04   \n",
       "25%    9.595000e+02                 0.000000         2.608932e+05   \n",
       "50%    2.555300e+04                 6.000000         3.954805e+05   \n",
       "75%    3.876305e+05                23.250000         6.948620e+05   \n",
       "max    4.266759e+07               411.000000         4.852193e+07   \n",
       "\n",
       "       shared_receipt_with_poi  restricted_stock  director_fees  \n",
       "count                72.000000      9.300000e+01   1.700000e+01  \n",
       "mean               1058.527778      2.322312e+06   1.668049e+05  \n",
       "std                1132.503757      1.354194e+07   3.198914e+05  \n",
       "min                   2.000000     -2.604490e+06   3.285000e+03  \n",
       "25%                 191.500000      2.130630e+05   9.878400e+04  \n",
       "50%                 594.000000      4.176190e+05   1.085790e+05  \n",
       "75%                1635.500000      9.340650e+05   1.137840e+05  \n",
       "max                4527.000000      1.303223e+08   1.398517e+06  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>loan_advances</th>\n",
       "      <th>bonus</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>total_stock_value</th>\n",
       "      <th>expenses</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>other</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>director_fees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7.800000e+01</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>3.400000e+01</td>\n",
       "      <td>1.070000e+02</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>6.600000e+01</td>\n",
       "      <td>1.800000e+01</td>\n",
       "      <td>3.800000e+01</td>\n",
       "      <td>1.080000e+02</td>\n",
       "      <td>7.700000e+01</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>9.000000e+01</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>7.500000e+01</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>5.400000e+01</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>9.300000e+01</td>\n",
       "      <td>1.700000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.011525e+05</td>\n",
       "      <td>2007.111111</td>\n",
       "      <td>1.807789e+06</td>\n",
       "      <td>4.605105e+06</td>\n",
       "      <td>2.877500e+07</td>\n",
       "      <td>2.446776e+06</td>\n",
       "      <td>1.664106e+05</td>\n",
       "      <td>-1.170917e+06</td>\n",
       "      <td>6.375339e+06</td>\n",
       "      <td>1.201496e+05</td>\n",
       "      <td>58.500000</td>\n",
       "      <td>5.390155e+06</td>\n",
       "      <td>668.763889</td>\n",
       "      <td>9.469212e+05</td>\n",
       "      <td>36.277778</td>\n",
       "      <td>1.529361e+06</td>\n",
       "      <td>1058.527778</td>\n",
       "      <td>2.322312e+06</td>\n",
       "      <td>1.668049e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.997169e+06</td>\n",
       "      <td>2693.165955</td>\n",
       "      <td>5.510228e+06</td>\n",
       "      <td>2.990485e+07</td>\n",
       "      <td>4.776800e+07</td>\n",
       "      <td>1.191776e+07</td>\n",
       "      <td>4.201494e+06</td>\n",
       "      <td>4.531597e+06</td>\n",
       "      <td>4.173084e+07</td>\n",
       "      <td>5.925085e+05</td>\n",
       "      <td>87.995198</td>\n",
       "      <td>3.275556e+07</td>\n",
       "      <td>1978.997801</td>\n",
       "      <td>4.983723e+06</td>\n",
       "      <td>85.139690</td>\n",
       "      <td>6.564217e+06</td>\n",
       "      <td>1132.503757</td>\n",
       "      <td>1.354194e+07</td>\n",
       "      <td>3.198914e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.770000e+02</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>-1.025000e+05</td>\n",
       "      <td>1.480000e+02</td>\n",
       "      <td>4.000000e+05</td>\n",
       "      <td>7.000000e+04</td>\n",
       "      <td>-7.576788e+06</td>\n",
       "      <td>-2.799289e+07</td>\n",
       "      <td>-4.409300e+04</td>\n",
       "      <td>1.480000e+02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.285000e+03</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.922300e+04</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-2.604490e+06</td>\n",
       "      <td>3.285000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.072158e+05</td>\n",
       "      <td>513.750000</td>\n",
       "      <td>8.746875e+04</td>\n",
       "      <td>3.410185e+05</td>\n",
       "      <td>1.200000e+06</td>\n",
       "      <td>4.000000e+05</td>\n",
       "      <td>-3.896218e+05</td>\n",
       "      <td>-5.812438e+05</td>\n",
       "      <td>4.282172e+05</td>\n",
       "      <td>1.883400e+04</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.507585e+05</td>\n",
       "      <td>20.500000</td>\n",
       "      <td>9.595000e+02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.608932e+05</td>\n",
       "      <td>191.500000</td>\n",
       "      <td>2.130630e+05</td>\n",
       "      <td>9.878400e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.545700e+05</td>\n",
       "      <td>944.000000</td>\n",
       "      <td>3.825325e+05</td>\n",
       "      <td>1.057548e+06</td>\n",
       "      <td>2.000000e+06</td>\n",
       "      <td>7.250000e+05</td>\n",
       "      <td>-1.469750e+05</td>\n",
       "      <td>-1.231420e+05</td>\n",
       "      <td>1.032338e+06</td>\n",
       "      <td>4.614500e+04</td>\n",
       "      <td>26.500000</td>\n",
       "      <td>1.043324e+06</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>2.555300e+04</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.954805e+05</td>\n",
       "      <td>594.000000</td>\n",
       "      <td>4.176190e+05</td>\n",
       "      <td>1.085790e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.002298e+05</td>\n",
       "      <td>2590.750000</td>\n",
       "      <td>1.066354e+06</td>\n",
       "      <td>2.031214e+06</td>\n",
       "      <td>4.296250e+07</td>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>-7.500975e+04</td>\n",
       "      <td>-3.708600e+04</td>\n",
       "      <td>2.372703e+06</td>\n",
       "      <td>7.855200e+04</td>\n",
       "      <td>61.750000</td>\n",
       "      <td>2.204999e+06</td>\n",
       "      <td>216.500000</td>\n",
       "      <td>3.876305e+05</td>\n",
       "      <td>23.250000</td>\n",
       "      <td>6.948620e+05</td>\n",
       "      <td>1635.500000</td>\n",
       "      <td>9.340650e+05</td>\n",
       "      <td>1.137840e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.670423e+07</td>\n",
       "      <td>15149.000000</td>\n",
       "      <td>3.208340e+07</td>\n",
       "      <td>3.098866e+08</td>\n",
       "      <td>8.392500e+07</td>\n",
       "      <td>9.734362e+07</td>\n",
       "      <td>1.545629e+07</td>\n",
       "      <td>-1.042000e+03</td>\n",
       "      <td>4.345095e+08</td>\n",
       "      <td>5.235198e+06</td>\n",
       "      <td>528.000000</td>\n",
       "      <td>3.117640e+08</td>\n",
       "      <td>14368.000000</td>\n",
       "      <td>4.266759e+07</td>\n",
       "      <td>411.000000</td>\n",
       "      <td>4.852193e+07</td>\n",
       "      <td>4527.000000</td>\n",
       "      <td>1.303223e+08</td>\n",
       "      <td>1.398517e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3>Example of data content for POI Kenneth Lay:</h3>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "sample_contents = data_dict['LAY KENNETH L']\r\n",
    "for k, v in sample_contents.items():\r\n",
    "    l = 45 - len(k)\r\n",
    "    dots = repeat_to_length('.', l)\r\n",
    "    print('\\t{0}: {1} {2}'.format(k, dots, v))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\tsalary: ....................................... 1072321\n",
      "\tto_messages: .................................. 4273\n",
      "\tdeferral_payments: ............................ 202911\n",
      "\ttotal_payments: ............................... 103559793\n",
      "\tloan_advances: ................................ 81525000\n",
      "\tbonus: ........................................ 7000000\n",
      "\temail_address: ................................ kenneth.lay@enron.com\n",
      "\trestricted_stock_deferred: .................... NaN\n",
      "\tdeferred_income: .............................. -300000\n",
      "\ttotal_stock_value: ............................ 49110078\n",
      "\texpenses: ..................................... 99832\n",
      "\tfrom_poi_to_this_person: ...................... 123\n",
      "\texercised_stock_options: ...................... 34348384\n",
      "\tfrom_messages: ................................ 36\n",
      "\tother: ........................................ 10359729\n",
      "\tfrom_this_person_to_poi: ...................... 16\n",
      "\tpoi: .......................................... True\n",
      "\tlong_term_incentive: .......................... 3600000\n",
      "\tshared_receipt_with_poi: ...................... 2411\n",
      "\trestricted_stock: ............................. 14761694\n",
      "\tdirector_fees: ................................ NaN\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3>Ratio of NaN entries per feature in dataset:</h3>\n",
    "\n",
    "<h4>Short Definition of Financial Terms</h4>\n",
    "\n",
    "><b>total_payments</b>: <i>Total payment is any payment or benefit received or to be received by the Executive in connection with a Change in Control or the termination of the Executive's employment.</i>[source: https://www.lawinsider.com/]\n",
    "\n",
    "><b>loan_advances</b>: <i>Loan Advance means a disbursement of all or any portion of the Loan.</i>[source: https://www.lawinsider.com/]\n",
    "\n",
    "><b>deferred_income</b>: <i>Deferred income (also known as deferred revenue, unearned revenue, or unearned income) is, in accrual accounting, money received for goods or services which has not yet been earned. According to the revenue recognition principle, it is recorded as a liability until delivery is made, at which time it is converted into revenue.</i>[source: https://en.wikipedia.org/wiki/Deferred_income]\n",
    "\n",
    "><b>bonus</b>: <i>A bonus payment is usually made to employees in addition to their base salary as part of their wages or salary. While the base salary usually is a fixed amount per month, bonus payments more often than not vary depending on known criteria, such as the annual turnover, or the net number of additional customers acquired, or the current value of the stock of a public company.</i>[source: https://en.wikipedia.org/wiki/Bonus_payment]\n",
    "\n",
    "><b>restricted_stock_deferred</b>: <i>Restricted stocks have specified limits with regard to the ability of the employee to monetize or access the stocks. While both deferred and restricted stocks may be subject to vesting requirements, resulting in a delay before the employee takes full ownership of the associated shares, restricted stocks are immediately converted to unrestricted shares once the period has ended, while deferred shares do not convert until a selected date beyond the vesting date.</i>[source: https://www.investopedia.com/terms/d/deferredshare.asp]\n",
    "\n",
    "><b>exercised_stock_options</b>: <i>RExercising a stock option means purchasing the issuer's common stock at the price set by the option (grant price), regardless of the stock's price at the time you exercise the option.</i>[source: https://www.fidelity.com/products/stockoptions/exercise.shtml]\n",
    "\n",
    "><b>long_term_incentive</b>: <i>A long-term incentive plan (LTIP) is a company policy that rewards employees for reaching specific goals that lead to increased shareholder value.</i>[source: https://www.investopedia.com/terms/l/long_term_incentive-plan.asp]"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "features_nan_counts = explore_obj.get_feature_nan_counts()\r\n",
    "df_features_nan_counts = pd.DataFrame(features_nan_counts.items())\r\n",
    "df_features_nan_counts.columns = ['Feature','NaN count']\r\n",
    "df_features_nan_counts.sort_values(by=['NaN count'], inplace=True)\r\n",
    "df_features_nan_counts.reset_index(drop=True, inplace=True)\r\n",
    "\r\n",
    "max_nan_count = df_features_nan_counts.iloc[len(df_features_nan_counts)-1]['NaN count']\r\n",
    "print('\\nMax NaN count: {}'.format(max_nan_count))\r\n",
    "df_features_nan_counts['ratio'] = df_features_nan_counts['NaN count']/max_nan_count\r\n",
    "print(df_features_nan_counts.to_string(index=False))\r\n",
    "\r\n",
    "#--- list features with more than selected percentage (%) of NaNs:\r\n",
    "thresh_ratio = 0.7\r\n",
    "rslt_df = df_features_nan_counts.loc[df_features_nan_counts['ratio'] > thresh_ratio]\r\n",
    "nan_features = rslt_df['Feature'].tolist()\r\n",
    "print('\\nFeatures with NaN > {} % will be excluded:'.format(thresh_ratio*100.0))\r\n",
    "print(nan_features)\r\n",
    "\r\n",
    "selected_features = []\r\n",
    "all_features = explore_obj.get_features()\r\n",
    "\r\n",
    "for feature in all_features:\r\n",
    "    if feature not in nan_features:\r\n",
    "        selected_features.append(feature)\r\n",
    "\r\n",
    "print('\\nselected features:\\n{}'.format(selected_features))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Max NaN count: 142\n",
      "                  Feature  NaN count    ratio\n",
      "                     Name          0 0.000000\n",
      "                      poi          0 0.000000\n",
      "        total_stock_value         20 0.140845\n",
      "           total_payments         21 0.147887\n",
      "            email_address         35 0.246479\n",
      "         restricted_stock         36 0.253521\n",
      "  exercised_stock_options         44 0.309859\n",
      "                   salary         51 0.359155\n",
      "                 expenses         51 0.359155\n",
      "                    other         53 0.373239\n",
      "  from_poi_to_this_person         60 0.422535\n",
      "            from_messages         60 0.422535\n",
      "  from_this_person_to_poi         60 0.422535\n",
      "  shared_receipt_with_poi         60 0.422535\n",
      "              to_messages         60 0.422535\n",
      "                    bonus         64 0.450704\n",
      "      long_term_incentive         80 0.563380\n",
      "          deferred_income         97 0.683099\n",
      "        deferral_payments        107 0.753521\n",
      "restricted_stock_deferred        128 0.901408\n",
      "            director_fees        129 0.908451\n",
      "            loan_advances        142 1.000000\n",
      "\n",
      "Features with NaN > 70.0 % will be excluded:\n",
      "['deferral_payments', 'restricted_stock_deferred', 'director_fees', 'loan_advances']\n",
      "\n",
      "selected features:\n",
      "['salary', 'to_messages', 'total_payments', 'bonus', 'email_address', 'deferred_income', 'total_stock_value', 'expenses', 'from_poi_to_this_person', 'exercised_stock_options', 'from_messages', 'other', 'from_this_person_to_poi', 'poi', 'long_term_incentive', 'shared_receipt_with_poi', 'restricted_stock', 'Name']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3>NaN entries per employee in dataset:</h3>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "df_employee_nan_counts = ((enron_df[all_features].isna()).sum(axis=1)).to_frame()\r\n",
    "df_employee_nan_counts['Name'] = df_employee_nan_counts.index\r\n",
    "df_employee_nan_counts.columns = ['NaN count', 'Name']\r\n",
    "df_employee_nan_counts = df_employee_nan_counts[['Name', 'NaN count']]\r\n",
    "df_employee_nan_counts['NaN %'] = (df_employee_nan_counts['NaN count'] / len(all_features))*100.\r\n",
    "df_employee_nan_counts.sort_values(by=['NaN count'], inplace=True)\r\n",
    "df_employee_nan_counts.reset_index(drop=True, inplace=True)\r\n",
    "df_employee_nan_counts"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                              Name  NaN count      NaN %\n",
       "0                    LAY KENNETH L          2   9.090909\n",
       "1                   FREVERT MARK A          2   9.090909\n",
       "2                  HAEDICKE MARK E          2   9.090909\n",
       "3                  ALLEN PHILLIP K          2   9.090909\n",
       "4              DERRICK JR. JAMES V          3  13.636364\n",
       "..                             ...        ...        ...\n",
       "141                   WROBEL BRUCE         18  81.818182\n",
       "142                 WHALEY DAVID A         18  81.818182\n",
       "143                  GRAMM WENDY L         18  81.818182\n",
       "144  THE TRAVEL AGENCY IN THE PARK         18  81.818182\n",
       "145              LOCKHART EUGENE E         20  90.909091\n",
       "\n",
       "[146 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>NaN count</th>\n",
       "      <th>NaN %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LAY KENNETH L</td>\n",
       "      <td>2</td>\n",
       "      <td>9.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FREVERT MARK A</td>\n",
       "      <td>2</td>\n",
       "      <td>9.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAEDICKE MARK E</td>\n",
       "      <td>2</td>\n",
       "      <td>9.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALLEN PHILLIP K</td>\n",
       "      <td>2</td>\n",
       "      <td>9.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DERRICK JR. JAMES V</td>\n",
       "      <td>3</td>\n",
       "      <td>13.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>WROBEL BRUCE</td>\n",
       "      <td>18</td>\n",
       "      <td>81.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>WHALEY DAVID A</td>\n",
       "      <td>18</td>\n",
       "      <td>81.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>GRAMM WENDY L</td>\n",
       "      <td>18</td>\n",
       "      <td>81.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>THE TRAVEL AGENCY IN THE PARK</td>\n",
       "      <td>18</td>\n",
       "      <td>81.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>LOCKHART EUGENE E</td>\n",
       "      <td>20</td>\n",
       "      <td>90.909091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>146 rows × 3 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "#--- Remove employees with NaN count > 90%\r\n",
    "empl_to_pop = df_employee_nan_counts.loc[df_employee_nan_counts['NaN %'] >90. , 'Name'].tolist()\r\n",
    "\r\n",
    "size_empl_to_pop = len(empl_to_pop)\r\n",
    "\r\n",
    "if size_empl_to_pop > 1:\r\n",
    "    print('\\nThe following employees have more than 90% NaN entries and will be ignored if non-POI:')\r\n",
    "    print(empl_to_pop)\r\n",
    "elif size_empl_to_pop == 1:\r\n",
    "    print('\\nThe following employee has more than 90% NaN entries and will be ignored if non-POI:')\r\n",
    "    print(empl_to_pop[0])\r\n",
    "else:\r\n",
    "    pass\r\n",
    "\r\n",
    "poi_list = explore_obj.get_poi_list()\r\n",
    "\r\n",
    "for empl in empl_to_pop:\r\n",
    "    if empl not in poi_list:\r\n",
    "        data_dict.pop(empl, 0)\r\n",
    "\r\n",
    "#--- remove 'TOTAL' point:\r\n",
    "print('\\nAlso \"TOTAL\" entry removed from data_dict')\r\n",
    "data_dict.pop('TOTAL', 0) \r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "The following employee has more than 90% NaN entries and will be ignored if non-POI:\n",
      "LOCKHART EUGENE E\n",
      "\n",
      "Also \"TOTAL\" entry removed from data_dict\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'salary': 26704229,\n",
       " 'to_messages': 'NaN',\n",
       " 'deferral_payments': 32083396,\n",
       " 'total_payments': 309886585,\n",
       " 'loan_advances': 83925000,\n",
       " 'bonus': 97343619,\n",
       " 'email_address': 'NaN',\n",
       " 'restricted_stock_deferred': -7576788,\n",
       " 'deferred_income': -27992891,\n",
       " 'total_stock_value': 434509511,\n",
       " 'expenses': 5235198,\n",
       " 'from_poi_to_this_person': 'NaN',\n",
       " 'exercised_stock_options': 311764000,\n",
       " 'from_messages': 'NaN',\n",
       " 'other': 42667589,\n",
       " 'from_this_person_to_poi': 'NaN',\n",
       " 'poi': False,\n",
       " 'long_term_incentive': 48521928,\n",
       " 'shared_receipt_with_poi': 'NaN',\n",
       " 'restricted_stock': 130322299,\n",
       " 'director_fees': 1398517}"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "#--- Remove features with NaN above threshhold from the dataset:\r\n",
    "\r\n",
    "def clean_features(dict, features_to_exclude):\r\n",
    "    clean_dict = {}\r\n",
    "    \r\n",
    "    for k, v in dict.items():\r\n",
    "        value_pair = v\r\n",
    "\r\n",
    "        inner_dict = {}\r\n",
    "        for k1, v1 in value_pair.items():\r\n",
    "            if k1 not in features_to_exclude:\r\n",
    "                inner_dict[k1] = v1\r\n",
    "\r\n",
    "        clean_dict[k] = copy.deepcopy(inner_dict)\r\n",
    "\r\n",
    "    return clean_dict\r\n",
    "\r\n",
    "data_dict = clean_features(data_dict, nan_features)"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "sample_contents = data_dict['BHATNAGAR SANJAY']\r\n",
    "for k, v in sample_contents.items():\r\n",
    "    l = 45 - len(k)\r\n",
    "    dots = repeat_to_length('.', l)\r\n",
    "    print('\\t{0}: {1} {2}'.format(k, dots, v))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\tsalary: ....................................... NaN\n",
      "\tto_messages: .................................. 523\n",
      "\ttotal_stock_value: ............................ NaN\n",
      "\ttotal_payments: ............................... 15456290\n",
      "\tbonus: ........................................ NaN\n",
      "\temail_address: ................................ sanjay.bhatnagar@enron.com\n",
      "\tdeferred_income: .............................. NaN\n",
      "\texpenses: ..................................... NaN\n",
      "\tfrom_poi_to_this_person: ...................... 0\n",
      "\texercised_stock_options: ...................... 2604490\n",
      "\tfrom_messages: ................................ 29\n",
      "\tother: ........................................ 137864\n",
      "\tfrom_this_person_to_poi: ...................... 1\n",
      "\tpoi: .......................................... False\n",
      "\tlong_term_incentive: .......................... NaN\n",
      "\tshared_receipt_with_poi: ...................... 463\n",
      "\trestricted_stock: ............................. -2604490\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "enron_df = (pd.DataFrame.from_dict(data_dict)).T\r\n",
    "enron_df.replace('NaN', np.nan, inplace=True)\r\n",
    "# enron_df\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "#--- Ref.: https://www.shanelynn.ie/pandas-iloc-loc-select-rows-and-columns-dataframe/\r\n",
    "#enron_df.loc['BHATNAGAR SANJAY']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "#--- create dataframe from updated dictionary dataset:\r\n",
    "explore_obj.convert_to_csv(data_dict)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'convert_to_csv' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-406a85f65adb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#--- create dataframe from updated dictionary dataset:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mconvert_to_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'convert_to_csv' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#--- further explore the new dataset by looking into each feature:\r\n",
    "\r\n",
    "#--- Money related features:\r\n",
    "financial_features = ['salary', 'total_payments', 'bonus', 'deferred_income', 'total_stock_value', \r\n",
    "    'expenses', 'exercised_stock_options', 'long_term_incentive', 'restricted_stock']\r\n",
    "\r\n",
    "#--- Email related features:\r\n",
    "email_features = ['from_poi_to_this_person','from_this_person_to_poi','from_messages',\r\n",
    "    'shared_receipt_with_poi','to_messages']\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def sns_boxplot(df, title, features, n, m):\r\n",
    "    '''\r\n",
    "    Create grid boxplot\r\n",
    "    - df = dataframe\r\n",
    "    - title = plot title\r\n",
    "    - features = list of features to consider\r\n",
    "    - n = number of rows for grid plot\r\n",
    "    - m = number of columns for grid plot\r\n",
    "    '''\r\n",
    "    #--- Ref: https://www.geeksforgeeks.org/multi-plot-grid-in-seaborn/\r\n",
    "    # n = 2\r\n",
    "    # m = 3\r\n",
    "\r\n",
    "    fig, axes = plt.subplots(n, m, figsize=(24, 10))\r\n",
    "    fig.suptitle(title)\r\n",
    "\r\n",
    "    k = 0\r\n",
    "    for i in range(n):\r\n",
    "        for j in range(m):\r\n",
    "            feature = features[k]\r\n",
    "            (pd.to_numeric(df[feature]).groupby(df['poi'])).mean()\r\n",
    "            sns.boxplot(ax=axes[i, j], data=df, x='poi', y=feature)\r\n",
    "            if (k+1) < len(features):\r\n",
    "                k+=1\r\n",
    "            else:\r\n",
    "                break"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3>Explore Enron Employee Financial Data</h3>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "sns_boxplot(enron_df, 'Box plot with Enron financial data', financial_features, 3, 3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3>Explore Enron Employee Email Data</h3>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#--- Explore email features:\r\n",
    "\r\n",
    "#--- Compare POI data vs non-POI data:\r\n",
    "sns_boxplot(enron_df, 'Box plot with Enron email data', email_features, 3, 3)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sns.lmplot(x='bonus', y= 'salary', hue='poi', data=enron_df, palette='Set2',size=10,markers=['x','+'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sns.lmplot(x='exercised_stock_options', y= 'salary', hue='poi', data=enron_df, palette='Set2',size=10,markers=['x','+'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>Question 2</h2>\r\n",
    "\r\n",
    " -- explain what feature you tried to make, and the rationale behind it. (You do not necessarily have to use it in the final analysis, only engineer and test it.) In your feature selection step, if you used an algorithm like a decision tree, please also give the feature importance of the features that you use, and if you used an automated feature selection function like SelectKBest, please report the feature scores and reasons for your choice of parameter values. [relevant rubric items: “create new features”, “intelligently select features”, “properly scale features”]"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#--cover\r\n",
    "\r\n",
    "### Create new feature(s)\r\n",
    "\r\n",
    "#add fraction of emails from and to poi\r\n",
    "#idea for this added feature taken from course materials\r\n",
    "\r\n",
    "def computeFraction( poi_messages, all_messages ):\r\n",
    "    \"\"\" given a number messages to/from POI (numerator) \r\n",
    "        and number of all messages to/from a person (denominator),\r\n",
    "        return the fraction of messages to/from that person\r\n",
    "        that are from/to a POI\r\n",
    "   \"\"\"\r\n",
    "    fraction = 0.\r\n",
    "    if poi_messages != 'NaN' and all_messages != 'NaN':\r\n",
    "        fraction = float(poi_messages)/all_messages\r\n",
    "\r\n",
    "\r\n",
    "    return fraction"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#--cover\r\n",
    "# \r\n",
    "enron_dict = data_dict\r\n",
    "for name in enron_dict:\r\n",
    "\r\n",
    "    data_point = enron_dict[name]\r\n",
    "\r\n",
    "    from_poi_to_this_person = data_point[\"from_poi_to_this_person\"]\r\n",
    "    to_messages = data_point[\"to_messages\"]\r\n",
    "    fraction_from_poi = computeFraction( from_poi_to_this_person, to_messages )\r\n",
    "    \r\n",
    "    enron_dict[name][\"fraction_from_poi\"] = fraction_from_poi\r\n",
    "  \r\n",
    "    from_this_person_to_poi = data_point[\"from_this_person_to_poi\"]\r\n",
    "    from_messages = data_point[\"from_messages\"]\r\n",
    "    fraction_to_poi = computeFraction( from_this_person_to_poi, from_messages )\r\n",
    "\r\n",
    "    enron_dict[name][\"fraction_to_poi\"] = fraction_to_poi"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#--- cover\r\n",
    "\r\n",
    "### Select what features to use\r\n",
    "first_list = ['poi','salary','fraction_to_poi','from_messages']\r\n",
    "second_list = ['poi','total_be','fraction_to_poi','from_messages']\r\n",
    "third_list = ['poi','salary','bonus','fraction_to_poi','from_messages']\r\n",
    "fourth_list = ['poi','bonus','exercised_stock_options','fraction_to_poi']\r\n",
    "\r\n",
    "features_final_list = fourth_list\r\n",
    "print(\"Final List\", features_final_list)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>Question 3</h2>\n",
    "\n",
    ">What algorithm did you end up using? What other one(s) did you try? How did model\n",
    "performance differ between algorithms? [relevant rubric item: “pick an algorithm”]"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#--cover\r\n",
    "\r\n",
    "#Evaluation metrics\r\n",
    "\r\n",
    "from sklearn.metrics import accuracy_score\r\n",
    "from sklearn.metrics import precision_score\r\n",
    "from sklearn.metrics import recall_score\r\n",
    "\r\n",
    "import scikitplot as skplt\r\n",
    "\r\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "#Classifiers\r\n",
    "from sklearn.naive_bayes import GaussianNB\r\n",
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "from sklearn.model_selection import GridSearchCV\r\n",
    "\r\n",
    "# %load 'my_test.py'\r\n",
    "def test_list(classifier, feature_list, enron_dict):\r\n",
    "    \r\n",
    "    my_dataset = enron_dict\r\n",
    "    \r\n",
    "    data = featureFormat(my_dataset, feature_list, sort_keys = True)\r\n",
    "    labels, features = targetFeatureSplit(data)\r\n",
    "\r\n",
    "    \r\n",
    "    X = np.array(features)\r\n",
    "    y = np.array(labels)\r\n",
    "\r\n",
    "    sss = StratifiedShuffleSplit(n_splits=10, test_size=0.3, random_state=42)\r\n",
    "\r\n",
    "   # sss.get_n_splits(X, y)\r\n",
    "\r\n",
    "    # for train_index, test_index in sss.split(X, y):\r\n",
    "    #     features_train, features_test = X[train_index], X[test_index]\r\n",
    "    #     labels_train, labels_test = y[train_index], y[test_index]\r\n",
    "    \r\n",
    "    features_train, features_test, labels_train, labels_test = train_test_split(X, y, test_size=0.33, random_state=42)\r\n",
    "\r\n",
    "    clf = classifier\r\n",
    "    clf.fit(features_train, labels_train)\r\n",
    "    pred = clf.predict(features_test)\r\n",
    "    \r\n",
    "    if classifier == DecisionTreeClassifier():\r\n",
    "        return {'Accuracy': accuracy_score(labels_test,pred),'Precision': precision_score(labels_test,pred, average='micro'),\r\n",
    "                'Recall': recall_score(labels_test,pred), 'Feature Importance': clf.feature_importances_}\r\n",
    "    \r\n",
    "    return {'Accuracy': accuracy_score(labels_test,pred),'Precision': precision_score(labels_test,pred, average='micro'),\r\n",
    "            'Recall': recall_score(labels_test,pred, average='micro')}\r\n",
    "    \r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#--cover\r\n",
    "\r\n",
    "#full list\r\n",
    "print(selected_features)\r\n",
    "print('GaussianNB: ', test_list(GaussianNB(), selected_features, data_dict))\r\n",
    "print('DecisionTree: ', test_list(DecisionTreeClassifier(), selected_features, data_dict))\r\n",
    "print('KNeighbors: ', test_list(KNeighborsClassifier(), selected_features, data_dict))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# cover\r\n",
    "#first list\r\n",
    "print(first_list)\r\n",
    "print('GaussianNB: ', test_list(GaussianNB(), first_list, data_dict))\r\n",
    "print('DecisionTree: ', test_list(DecisionTreeClassifier(), first_list, data_dict))\r\n",
    "print('KNeighbors: ', test_list(KNeighborsClassifier(), first_list, data_dict))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>Question 4</h2>\n",
    "\n",
    ">What does it mean to tune the parameters of an algorithm, and what can happen if you don’t do this well? How did you tune the parameters of your particular algorithm? What parameters did you tune? (Some algorithms do not have parameters that you need to tune -- if this is the case for the one you picked, identify and briefly explain how you would have done it for the model that was not your final choice or a different model that does utilize parameter tuning, e.g. a decision tree classifier). [relevant rubric items: “discuss parameter tuning”, “tune the algorithm”]"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#--- cover\r\n",
    "\r\n",
    "In machine learning, a hyper-parameter is a parameter whose value is set before the learning process begins. The process of setting the values of these parameters for a learning algorithm either by using model defaults, grid search, and random search or Bayesian optimization is called tuning. The tunable parameters of the models can greatly affect their accuracy, without doing this well, the model will not optimally solve the machine learning problem. The more tuned the parameters of an algorithm, the more biased the algorithm will behave relative to the training and test dataset. This approach can be effective, but it can also lead to a very fragile models that over fit the test data, hence, performing poorly in practice.\r\n",
    "\r\n",
    "My final algorithm was decision tree, studying the arrays of tunable parameters for decision; I found no strategic advantage or reason to modify the default, so I used the default parameters without further tuning. However, for other algorithm like SVM, I experimented with grid search using the following parameters set: {'kernel': ('linear', 'rbf'), 'C': [1, 10]} With adaboost, the parameters I tuned were : n_estimators=1000, random_state=202, learning_rate=1.0, algorithm=\"SAMME.R\" Generally, the approaches I used for tuning the parameters divides into two: an automatic approach using GridSearchCV and manual intelligent search approach."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>Question 5</h2>\n",
    "\n",
    ">What is validation, and what’s a classic mistake you can make if you do it wrong? How did you validate your analysis? [relevant rubric items: “discuss validation”, “validation strategy”]"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\r\n",
    "#--- cover\r\n",
    "\r\n",
    "Validation is the process of testing to see that your algorithm is doing according to specification what it is intended to do. This process determines if the algorithm will fit well outside the dataset provided i.e. it generalizes. A classis mistake in validation is overfitting. Overfitting occurs when:\r\n",
    "\r\n",
    "i. An algorithm is trained and tested on the same dataset: a model that would just repeat the labels of the samples that it has just seen would have a perfect score but would fail to predict anything useful on yet-unseen data. ii. An algorithm is so tuned that it’s sensitive to small fluctuations in the training set, resulting to high variance error. The algorithm model random noise in the training data, rather than the intended outputs (overfitting).\r\n",
    "\r\n",
    "How did you validate your analysis ?\r\n",
    "\r\n",
    "I shared available data into training, testing, and validation sets. The validation strategies I used are listed below. Note that the main difference is the number of split being done per time:\r\n",
    "\r\n",
    "Holdout: n groups = 1; Data is divided into two frames: training data frames and validation data frame. In any of the methods, one sample goes into the training set while the other into the test set. So the samples do not overlap, if they do, we just can’t trust our validation.\r\n",
    "Sklearn.model_selection.shufflesplit\r\n",
    "K-fold: K-fold can be viewed as a repeated holdout, because we split our data into k parts and iterate through them, using every part as a validation set only one. After this procedure, we average scores over these k-folds. It is important to understand the difference between k-fold and usual holdout or bits of k-times. While it is possible to average scores they receive after k different holdouts. In this case, some samples may never get invalidation, while others can be there multiple times. On the other side, the core idea of k-fold is that we want to use every sample for validation only one. This is method is a good choice when we have have a minimum amount of data, and we can get either a sufficiently big difference in quality, or different optimal parameters between folds.\r\n",
    "Leave-one-out: A special case of K-fold where k is the number of samples in our data. This means it will iterate through every sample in our data. Each time using k-1 object is a train subset and object left is a test subject. This method can be helpful when we have too little data and just enough model to train.\r\n",
    "Stratification preserves the same target distribution over different folds."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>Question 6</h2>\n",
    "\n",
    ">Give at least 2 evaluation metrics and your average performance for each of them.\n",
    "Explain an interpretation of your metrics that says something human-understandable\n",
    "about your algorithm’s performance. [relevant rubric item: “usage of evaluation metrics”]"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#--- cover\r\n",
    "\r\n",
    "The two evaluations metric I used were precision and recall. While precision defines the ratio of true positives relative to all positives (true positive + false positive), i.e.\r\n",
    "\r\n",
    "Precision=(True Positive)/(( True Positive+False positive ))\r\n",
    "\r\n",
    "Recall (or sensitivity of the algorithm) on the other hand defines the ratio of true positives relative to true positives and false negatives, i.e.\r\n",
    "\r\n",
    "Recall=(True Positives)/(( True Positives+False Negatives ))\r\n",
    "\r\n",
    "Average performance for precision and recall for all the experimented algorithms is detailed in experimental result as shown in Table 2 above."
   ],
   "metadata": {}
  }
 ]
}