{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3810jvsc74a57bd0656e8c145790dc01ffbdee7e88051232faf734f8f260b2714d321c382ec0bd4f",
   "display_name": "Python 3.8.10 64-bit ('nano_p4': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "656e8c145790dc01ffbdee7e88051232faf734f8f260b2714d321c382ec0bd4f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append(\"../tools/\")\n",
    "# sys.path.append(\"../dataset/\")\n",
    "sys.path.append(\"../data_wrangling/\")\n",
    "\n",
    "from data_explorer import explorer\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "source": [
    "<h2>Question 1</h2>\n",
    "\n",
    ">Summarize for us the goal of this project and how machine learning is useful in trying to accomplish it. As part of your answer, give some background on the dataset and how it can be used to answer the project question. Were there any outliers in the data when you got it, and how did you handle those? [Relevant rubric items: “data exploration”, “outlier investigation”]\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<h2>Setting up data for analysis</h2>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {}\n",
    "dataset = '../dataset/final_project_dataset.pkl'\n",
    "\n",
    "#--- extract dictionary from dataset:\n",
    "with open(dataset, 'rb') as data_file:\n",
    "    data_dict = pickle.load(data_file)"
   ]
  },
  {
   "source": [
    "\n",
    "<h3>Write dataset to csv file:</h3>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_csv(data_dict, excluded_features = []):\n",
    "    #--- Save dataset as CSV\n",
    "\n",
    "    # Create ouput directory if it doesn't already exist:\n",
    "    outdirname = '../output'\n",
    "    try:\n",
    "        os.makedirs(outdirname)\n",
    "        print('\\nDirectory \"{}\" created'.format(outdirname))\n",
    "    except FileExistsError:\n",
    "        print('\\nDirectory \"{}\" already exists - nothing done.'.format(outdirname))\n",
    "\n",
    "    csvfilename = outdirname + '/enron_data.csv'\n",
    "\n",
    "    with open(csvfilename, 'w') as csv_file:\n",
    "        print('\\nWriting data set to ../{}'.format(csvfilename))\n",
    "        writer = csv.writer(csv_file)\n",
    "\n",
    "        #--- create header:\n",
    "        header_line = ['Name']\n",
    "\n",
    "        for name in data_dict.keys():\n",
    "            if name != 'TOTAL':\n",
    "                value_pairs = data_dict[name]\n",
    "\n",
    "                for feature_value in value_pairs.keys():\n",
    "                    if feature_value not in excluded_features:\n",
    "                        header_line.append(feature_value)\n",
    "\n",
    "                break\n",
    "\n",
    "        writer.writerow(header_line)\n",
    "\n",
    "        for name in data_dict.keys():\n",
    "            line = []\n",
    "            line.append(name)\n",
    "\n",
    "            for k, v in data_dict[name].items():\n",
    "                if k not in excluded_features:\n",
    "                    line.append(v)\n",
    "\n",
    "            writer.writerow(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nDirectory \"../output\" already exists - nothing done.\n\nWriting data set to ../../output/enron_data.csv\n"
     ]
    }
   ],
   "source": [
    "convert_to_csv(data_dict)"
   ]
  },
  {
   "source": [
    "<h2>Data Exploration</h2>\n",
    "<h3>Summary of information contained in the dataset:</h3>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "METTS MARK              0.0\n",
      "BAXTER JOHN C           0.0\n",
      "ELLIOTT STEVEN          0.0\n",
      "CORDES WILLIAM R        0.0\n",
      "HANNON KEVIN P          0.0\n",
      "                       ... \n",
      "GRAMM WENDY L           0.0\n",
      "CAUSEY RICHARD A        0.0\n",
      "TAYLOR MITCHELL S       0.0\n",
      "DONAHUE JR JEFFREY M    0.0\n",
      "GLISAN JR BEN F         0.0\n",
      "Length: 146, dtype: float64\n",
      "\tNumber of individuals: ........................ 146\n",
      "\tNames: ........................................ ['METTS MARK', 'BAXTER JOHN C', 'ELLIOTT STEVEN', 'CORDES WILLIAM R', 'HANNON KEVIN P', 'MORDAUNT KRISTINA M', 'MEYER ROCKFORD G', 'MCMAHON JEFFREY', 'HAEDICKE MARK E', 'PIPER GREGORY F', 'HUMPHREY GENE E', 'NOLES JAMES L', 'BLACHMAN JEREMY M', 'SUNDE MARTIN', 'GIBBS DANA R', 'LOWRY CHARLES P', 'COLWELL WESLEY', 'MULLER MARK S', 'JACKSON CHARLENE R', 'WESTFAHL RICHARD K', 'WALTERS GARETH W', 'WALLS JR ROBERT H', 'KITCHEN LOUISE', 'CHAN RONNIE', 'BELFER ROBERT', 'SHANKMAN JEFFREY A', 'WODRASKA JOHN', 'BERGSIEKER RICHARD P', 'URQUHART JOHN A', 'BIBI PHILIPPE A', 'RIEKER PAULA H', 'WHALEY DAVID A', 'BECK SALLY W', 'HAUG DAVID L', 'ECHOLS JOHN B', 'MENDELSOHN JOHN', 'HICKERSON GARY J', 'CLINE KENNETH W', 'LEWIS RICHARD', 'HAYES ROBERT E', 'KOPPER MICHAEL J', 'LEFF DANIEL P', 'LAVORATO JOHN J', 'BERBERIAN DAVID', 'DETMERING TIMOTHY J', 'WAKEHAM JOHN', 'POWERS WILLIAM', 'GOLD JOSEPH', 'BANNANTINE JAMES M', 'DUNCAN JOHN H', 'SHAPIRO RICHARD S', 'SHERRIFF JOHN R', 'SHELBY REX', 'LEMAISTRE CHARLES', 'DEFFNER JOSEPH M', 'KISHKILL JOSEPH G', 'WHALLEY LAWRENCE G', 'MCCONNELL MICHAEL S', 'PIRO JIM', 'DELAINEY DAVID W', 'SULLIVAN-SHAKLOVITZ COLLEEN', 'WROBEL BRUCE', 'LINDHOLM TOD A', 'MEYER JEROME J', 'LAY KENNETH L', 'BUTTS ROBERT H', 'OLSON CINDY K', 'MCDONALD REBECCA', 'CUMBERLAND MICHAEL S', 'GAHN ROBERT S', 'BADUM JAMES P', 'HERMANN ROBERT J', 'FALLON JAMES B', 'GATHMANN WILLIAM D', 'HORTON STANLEY C', 'BOWEN JR RAYMOND M', 'GILLIS JOHN', 'FITZGERALD JAY L', 'MORAN MICHAEL P', 'REDMOND BRIAN L', 'BAZELIDES PHILIP J', 'BELDEN TIMOTHY N', 'DIMICHELE RICHARD G', 'DURAN WILLIAM D', 'THORN TERENCE H', 'FASTOW ANDREW S', 'FOY JOE', 'CALGER CHRISTOPHER F', 'RICE KENNETH D', 'KAMINSKI WINCENTY J', 'LOCKHART EUGENE E', 'COX DAVID', 'OVERDYKE JR JERE C', 'PEREIRA PAULO V. FERRAZ', 'STABLER FRANK', 'SKILLING JEFFREY K', 'BLAKE JR. NORMAN P', 'SHERRICK JEFFREY B', 'PRENTICE JAMES', 'GRAY RODNEY', 'THE TRAVEL AGENCY IN THE PARK', 'UMANOFF ADAM S', 'KEAN STEVEN J', 'TOTAL', 'FOWLER PEGGY', 'WASAFF GEORGE', 'WHITE JR THOMAS E', 'CHRISTODOULOU DIOMEDES', 'ALLEN PHILLIP K', 'SHARP VICTORIA T', 'JAEDICKE ROBERT', 'WINOKUR JR. HERBERT S', 'BROWN MICHAEL', 'MCCLELLAN GEORGE', 'HUGHES JAMES A', 'REYNOLDS LAWRENCE', 'PICKERING MARK R', 'BHATNAGAR SANJAY', 'CARTER REBECCA C', 'BUCHANAN HAROLD G', 'YEAP SOON', 'MURRAY JULIA H', 'GARLAND C KEVIN', 'DODSON KEITH', 'YEAGER F SCOTT', 'HIRKO JOSEPH', 'DIETRICH JANET R', 'DERRICK JR. JAMES V', 'FREVERT MARK A', 'PAI LOU L', 'HAYSLETT RODERICK J', 'BAY FRANKLIN R', 'MCCARTY DANNY J', 'FUGH JOHN L', 'SCRIMSHAW MATTHEW', 'KOENIG MARK E', 'SAVAGE FRANK', 'IZZO LAWRENCE L', 'TILNEY ELIZABETH A', 'MARTIN AMANDA K', 'BUY RICHARD B', 'GRAMM WENDY L', 'CAUSEY RICHARD A', 'TAYLOR MITCHELL S', 'DONAHUE JR JEFFREY M', 'GLISAN JR BEN F']\n",
      "\tNumber of features: ........................... 22\n",
      "\tNumber of POIs: ............................... 18\n",
      "\tPOI list: ..................................... ['HANNON KEVIN P', 'COLWELL WESLEY', 'RIEKER PAULA H', 'KOPPER MICHAEL J', 'SHELBY REX', 'DELAINEY DAVID W', 'LAY KENNETH L', 'BOWEN JR RAYMOND M', 'BELDEN TIMOTHY N', 'FASTOW ANDREW S', 'CALGER CHRISTOPHER F', 'RICE KENNETH D', 'SKILLING JEFFREY K', 'YEAGER F SCOTT', 'HIRKO JOSEPH', 'KOENIG MARK E', 'CAUSEY RICHARD A', 'GLISAN JR BEN F']\n",
      "\tNumber of non POIs: ........................... 128\n",
      "\tFolks with salary: ............................ 95\n",
      "\tNumber of Folks with NaN salary: .............. 21\n",
      "\tPercentage of Folks with NaN salary (%): ...... 14.383561643835616\n",
      "\tNumber of POIs with NaN salary: ............... 0\n",
      "\tPercentage of POIs with NaN salary (%): ....... 0.0\n",
      "/home/dan/Dokumente/nanodegree/p4/main/../data_wrangling/data_explorer.py:66: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  self.enron_df = self.enron_df.replace('NaN', pd.np.nan)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#--- explore data:\n",
    "explore_obj = explorer(data_dict)\n",
    "\n",
    "def repeat_to_length(string_to_expand, length):\n",
    "    return (string_to_expand * (int(length/len(string_to_expand))+1))[:length]\n",
    "\n",
    "parameters = explore_obj.get_dataset_parameters()\n",
    "for k,v in parameters.items():\n",
    "    if k != 'Features with NaN':\n",
    "        l = 45 - len(k)\n",
    "        dots = repeat_to_length('.', l)\n",
    "        print('\\t{0}: {1} {2}'.format(k, dots, v))\n"
   ]
  },
  {
   "source": [
    "<h3>Dataset statistical information:</h3>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nIndex: 146 entries, METTS MARK to GLISAN JR BEN F\nData columns (total 22 columns):\n #   Column                     Non-Null Count  Dtype  \n---  ------                     --------------  -----  \n 0   salary                     95 non-null     float64\n 1   to_messages                86 non-null     float64\n 2   deferral_payments          39 non-null     float64\n 3   total_payments             125 non-null    float64\n 4   loan_advances              4 non-null      float64\n 5   bonus                      82 non-null     float64\n 6   email_address              111 non-null    object \n 7   restricted_stock_deferred  18 non-null     float64\n 8   deferred_income            49 non-null     float64\n 9   total_stock_value          126 non-null    float64\n 10  expenses                   95 non-null     float64\n 11  from_poi_to_this_person    86 non-null     float64\n 12  exercised_stock_options    102 non-null    float64\n 13  from_messages              86 non-null     float64\n 14  other                      93 non-null     float64\n 15  from_this_person_to_poi    86 non-null     float64\n 16  poi                        146 non-null    bool   \n 17  long_term_incentive        66 non-null     float64\n 18  shared_receipt_with_poi    86 non-null     float64\n 19  restricted_stock           110 non-null    float64\n 20  director_fees              17 non-null     float64\n 21  Name                       146 non-null    object \ndtypes: bool(1), float64(19), object(2)\nmemory usage: 25.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Create dataframe from Enron data_dict:\n",
    "enron_df = explore_obj.get_dataframe()\n",
    "enron_df.info()"
   ]
  },
  {
   "source": [
    "<h3>Example of data content for POI Kenneth Lay:</h3>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\tsalary: ....................................... 1072321\n\tto_messages: .................................. 4273\n\tdeferral_payments: ............................ 202911\n\ttotal_payments: ............................... 103559793\n\tloan_advances: ................................ 81525000\n\tbonus: ........................................ 7000000\n\temail_address: ................................ kenneth.lay@enron.com\n\trestricted_stock_deferred: .................... NaN\n\tdeferred_income: .............................. -300000\n\ttotal_stock_value: ............................ 49110078\n\texpenses: ..................................... 99832\n\tfrom_poi_to_this_person: ...................... 123\n\texercised_stock_options: ...................... 34348384\n\tfrom_messages: ................................ 36\n\tother: ........................................ 10359729\n\tfrom_this_person_to_poi: ...................... 16\n\tpoi: .......................................... True\n\tlong_term_incentive: .......................... 3600000\n\tshared_receipt_with_poi: ...................... 2411\n\trestricted_stock: ............................. 14761694\n\tdirector_fees: ................................ NaN\n"
     ]
    }
   ],
   "source": [
    "sample_contents = data_dict['LAY KENNETH L']\n",
    "for k, v in sample_contents.items():\n",
    "    l = 45 - len(k)\n",
    "    dots = repeat_to_length('.', l)\n",
    "    print('\\t{0}: {1} {2}'.format(k, dots, v))"
   ]
  },
  {
   "source": [
    "<h3>Ratio of NaN entries per feature in dataset:</h3>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nMax NaN count: 142\n                  Feature  NaN count    ratio\n                     Name          0 0.000000\n                      poi          0 0.000000\n        total_stock_value         20 0.140845\n           total_payments         21 0.147887\n            email_address         35 0.246479\n         restricted_stock         36 0.253521\n  exercised_stock_options         44 0.309859\n                   salary         51 0.359155\n                 expenses         51 0.359155\n                    other         53 0.373239\n  from_poi_to_this_person         60 0.422535\n            from_messages         60 0.422535\n  from_this_person_to_poi         60 0.422535\n  shared_receipt_with_poi         60 0.422535\n              to_messages         60 0.422535\n                    bonus         64 0.450704\n      long_term_incentive         80 0.563380\n          deferred_income         97 0.683099\n        deferral_payments        107 0.753521\nrestricted_stock_deferred        128 0.901408\n            director_fees        129 0.908451\n            loan_advances        142 1.000000\n\nFeatures with NaN > 70.0 % will be excluded:\n['deferral_payments', 'restricted_stock_deferred', 'director_fees', 'loan_advances']\n\nselected features:\n['salary', 'to_messages', 'total_payments', 'bonus', 'email_address', 'deferred_income', 'total_stock_value', 'expenses', 'from_poi_to_this_person', 'exercised_stock_options', 'from_messages', 'other', 'from_this_person_to_poi', 'poi', 'long_term_incentive', 'shared_receipt_with_poi', 'restricted_stock', 'Name']\n"
     ]
    }
   ],
   "source": [
    "features_nan_counts = explore_obj.get_feature_nan_counts()\n",
    "df_features_nan_counts = pd.DataFrame(features_nan_counts.items())\n",
    "df_features_nan_counts.columns = ['Feature','NaN count']\n",
    "df_features_nan_counts.sort_values(by=['NaN count'], inplace=True)\n",
    "df_features_nan_counts.reset_index(drop=True, inplace=True)\n",
    "\n",
    "max_nan_count = df_features_nan_counts.iloc[len(df_features_nan_counts)-1]['NaN count']\n",
    "print('\\nMax NaN count: {}'.format(max_nan_count))\n",
    "df_features_nan_counts['ratio'] = df_features_nan_counts['NaN count']/max_nan_count\n",
    "print(df_features_nan_counts.to_string(index=False))\n",
    "\n",
    "#--- list features with more than selected percentage (%) NaNs:\n",
    "thresh_ratio = 0.7\n",
    "rslt_df = df_features_nan_counts.loc[df_features_nan_counts['ratio'] > thresh_ratio]\n",
    "nan_features = rslt_df['Feature'].tolist()\n",
    "print('\\nFeatures with NaN > {} % will be excluded:'.format(thresh_ratio*100.0))\n",
    "print(nan_features)\n",
    "\n",
    "selected_features = []\n",
    "all_features = explore_obj.get_features()\n",
    "\n",
    "for feature in all_features:\n",
    "    if feature not in nan_features:\n",
    "        selected_features.append(feature)\n",
    "\n",
    "print('\\nselected features:\\n{}'.format(selected_features))"
   ]
  },
  {
   "source": [
    "<h3>NaN entries per employee in dataset:</h3>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "df_employee_nan_counts = ((enron_df[all_features].isna()).sum(axis=1)).to_frame()\n",
    "df_employee_nan_counts['Name'] = df_employee_nan_counts.index\n",
    "df_employee_nan_counts.columns = ['NaN count', 'Name']\n",
    "df_employee_nan_counts = df_employee_nan_counts[['Name', 'NaN count']]\n",
    "df_employee_nan_counts['NaN %'] = (df_employee_nan_counts['NaN count'] / len(all_features))*100.\n",
    "df_employee_nan_counts.sort_values(by=['NaN count'], inplace=True)\n",
    "df_employee_nan_counts.reset_index(drop=True, inplace=True)\n",
    "df_employee_nan_counts"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                              Name  NaN count      NaN %\n",
       "0                    LAY KENNETH L          2   9.090909\n",
       "1                   FREVERT MARK A          2   9.090909\n",
       "2                  HAEDICKE MARK E          2   9.090909\n",
       "3                  ALLEN PHILLIP K          2   9.090909\n",
       "4              DERRICK JR. JAMES V          3  13.636364\n",
       "..                             ...        ...        ...\n",
       "141                   WROBEL BRUCE         18  81.818182\n",
       "142                 WHALEY DAVID A         18  81.818182\n",
       "143                  GRAMM WENDY L         18  81.818182\n",
       "144  THE TRAVEL AGENCY IN THE PARK         18  81.818182\n",
       "145              LOCKHART EUGENE E         20  90.909091\n",
       "\n",
       "[146 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>NaN count</th>\n      <th>NaN %</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>LAY KENNETH L</td>\n      <td>2</td>\n      <td>9.090909</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>FREVERT MARK A</td>\n      <td>2</td>\n      <td>9.090909</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>HAEDICKE MARK E</td>\n      <td>2</td>\n      <td>9.090909</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ALLEN PHILLIP K</td>\n      <td>2</td>\n      <td>9.090909</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>DERRICK JR. JAMES V</td>\n      <td>3</td>\n      <td>13.636364</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>141</th>\n      <td>WROBEL BRUCE</td>\n      <td>18</td>\n      <td>81.818182</td>\n    </tr>\n    <tr>\n      <th>142</th>\n      <td>WHALEY DAVID A</td>\n      <td>18</td>\n      <td>81.818182</td>\n    </tr>\n    <tr>\n      <th>143</th>\n      <td>GRAMM WENDY L</td>\n      <td>18</td>\n      <td>81.818182</td>\n    </tr>\n    <tr>\n      <th>144</th>\n      <td>THE TRAVEL AGENCY IN THE PARK</td>\n      <td>18</td>\n      <td>81.818182</td>\n    </tr>\n    <tr>\n      <th>145</th>\n      <td>LOCKHART EUGENE E</td>\n      <td>20</td>\n      <td>90.909091</td>\n    </tr>\n  </tbody>\n</table>\n<p>146 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nThe following employee has more than 90% NaN entries and will be ignored if non-POI:\nLOCKHART EUGENE E\n\nAlso \"TOTAL\" entry removed from data_dict\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'salary': 26704229,\n",
       " 'to_messages': 'NaN',\n",
       " 'deferral_payments': 32083396,\n",
       " 'total_payments': 309886585,\n",
       " 'loan_advances': 83925000,\n",
       " 'bonus': 97343619,\n",
       " 'email_address': 'NaN',\n",
       " 'restricted_stock_deferred': -7576788,\n",
       " 'deferred_income': -27992891,\n",
       " 'total_stock_value': 434509511,\n",
       " 'expenses': 5235198,\n",
       " 'from_poi_to_this_person': 'NaN',\n",
       " 'exercised_stock_options': 311764000,\n",
       " 'from_messages': 'NaN',\n",
       " 'other': 42667589,\n",
       " 'from_this_person_to_poi': 'NaN',\n",
       " 'poi': False,\n",
       " 'long_term_incentive': 48521928,\n",
       " 'shared_receipt_with_poi': 'NaN',\n",
       " 'restricted_stock': 130322299,\n",
       " 'director_fees': 1398517}"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "#--- Remove employees with NaN count > 90%\n",
    "empl_to_pop = df_employee_nan_counts.loc[df_employee_nan_counts['NaN %'] >90. , 'Name'].tolist()\n",
    "\n",
    "size_empl_to_pop = len(empl_to_pop)\n",
    "\n",
    "if size_empl_to_pop > 1:\n",
    "    print('\\nThe following employees have more than 90% NaN entries and will be ignored if non-POI:')\n",
    "    print(empl_to_pop)\n",
    "elif size_empl_to_pop == 1:\n",
    "    print('\\nThe following employee has more than 90% NaN entries and will be ignored if non-POI:')\n",
    "    print(empl_to_pop[0])\n",
    "else:\n",
    "    pass\n",
    "\n",
    "poi_list = explore_obj.get_poi_list()\n",
    "\n",
    "for empl in empl_to_pop:\n",
    "    if empl not in poi_list:\n",
    "        data_dict.pop(empl, 0)\n",
    "\n",
    "#--- remove 'TOTAL' point:\n",
    "print('\\nAlso \"TOTAL\" entry removed from data_dict')\n",
    "data_dict.pop('TOTAL', 0) \n"
   ]
  },
  {
   "source": [
    "#--- Remove features with NaN above threshhold from the dataset:\n",
    "\n",
    "def clean_features(dict, features_to_exclude):\n",
    "    clean_dict = {}\n",
    "    \n",
    "    for k, v in dict.items():\n",
    "        value_pair = v\n",
    "\n",
    "        inner_dict = {}\n",
    "        for k1, v1 in value_pair.items():\n",
    "            if k1 not in features_to_exclude:\n",
    "                inner_dict[k1] = v1\n",
    "\n",
    "        clean_dict[k] = copy.deepcopy(inner_dict)\n",
    "\n",
    "    return clean_dict\n",
    "\n",
    "data_dict = clean_features(data_dict, nan_features)"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                      salary to_messages total_payments    bonus  \\\n",
       "METTS MARK            365788         807        1061827   600000   \n",
       "BAXTER JOHN C         267102         NaN        5634343  1200000   \n",
       "ELLIOTT STEVEN        170941         NaN         211725   350000   \n",
       "CORDES WILLIAM R         NaN         764            NaN      NaN   \n",
       "HANNON KEVIN P        243293        1045         288682  1500000   \n",
       "...                      ...         ...            ...      ...   \n",
       "GRAMM WENDY L            NaN         NaN         119292      NaN   \n",
       "CAUSEY RICHARD A      415189        1892        1868758  1000000   \n",
       "TAYLOR MITCHELL S     265214         533        1092663   600000   \n",
       "DONAHUE JR JEFFREY M  278601         865         875760   800000   \n",
       "GLISAN JR BEN F       274975         873        1272284   600000   \n",
       "\n",
       "                                  email_address deferred_income  \\\n",
       "METTS MARK                 mark.metts@enron.com             NaN   \n",
       "BAXTER JOHN C                               NaN        -1386055   \n",
       "ELLIOTT STEVEN         steven.elliott@enron.com         -400729   \n",
       "CORDES WILLIAM R          bill.cordes@enron.com             NaN   \n",
       "HANNON KEVIN P           kevin.hannon@enron.com        -3117011   \n",
       "...                                         ...             ...   \n",
       "GRAMM WENDY L                               NaN             NaN   \n",
       "CAUSEY RICHARD A       richard.causey@enron.com         -235000   \n",
       "TAYLOR MITCHELL S     mitchell.taylor@enron.com             NaN   \n",
       "DONAHUE JR JEFFREY M     jeff.donahue@enron.com         -300000   \n",
       "GLISAN JR BEN F            ben.glisan@enron.com             NaN   \n",
       "\n",
       "                     total_stock_value expenses from_poi_to_this_person  \\\n",
       "METTS MARK                      585062    94299                      38   \n",
       "BAXTER JOHN C                 10623258    11200                     NaN   \n",
       "ELLIOTT STEVEN                 6678735    78552                     NaN   \n",
       "CORDES WILLIAM R               1038185      NaN                      10   \n",
       "HANNON KEVIN P                 6391065    34039                      32   \n",
       "...                                ...      ...                     ...   \n",
       "GRAMM WENDY L                      NaN      NaN                     NaN   \n",
       "CAUSEY RICHARD A               2502063    30674                      58   \n",
       "TAYLOR MITCHELL S              3745048      NaN                       0   \n",
       "DONAHUE JR JEFFREY M           1080988    96268                     188   \n",
       "GLISAN JR BEN F                 778546   125978                      52   \n",
       "\n",
       "                     exercised_stock_options from_messages    other  \\\n",
       "METTS MARK                               NaN            29     1740   \n",
       "BAXTER JOHN C                        6680544           NaN  2660303   \n",
       "ELLIOTT STEVEN                       4890344           NaN    12961   \n",
       "CORDES WILLIAM R                      651850            12      NaN   \n",
       "HANNON KEVIN P                       5538001            32    11350   \n",
       "...                                      ...           ...      ...   \n",
       "GRAMM WENDY L                            NaN           NaN      NaN   \n",
       "CAUSEY RICHARD A                         NaN            49   307895   \n",
       "TAYLOR MITCHELL S                    3181250            29      NaN   \n",
       "DONAHUE JR JEFFREY M                  765920            22      891   \n",
       "GLISAN JR BEN F                       384728            16   200308   \n",
       "\n",
       "                     from_this_person_to_poi    poi long_term_incentive  \\\n",
       "METTS MARK                                 1  False                 NaN   \n",
       "BAXTER JOHN C                            NaN  False             1586055   \n",
       "ELLIOTT STEVEN                           NaN  False                 NaN   \n",
       "CORDES WILLIAM R                           0  False                 NaN   \n",
       "HANNON KEVIN P                            21   True             1617011   \n",
       "...                                      ...    ...                 ...   \n",
       "GRAMM WENDY L                            NaN  False                 NaN   \n",
       "CAUSEY RICHARD A                          12   True              350000   \n",
       "TAYLOR MITCHELL S                          0  False                 NaN   \n",
       "DONAHUE JR JEFFREY M                      11  False                 NaN   \n",
       "GLISAN JR BEN F                            6   True               71023   \n",
       "\n",
       "                     shared_receipt_with_poi restricted_stock  \n",
       "METTS MARK                               702           585062  \n",
       "BAXTER JOHN C                            NaN          3942714  \n",
       "ELLIOTT STEVEN                           NaN          1788391  \n",
       "CORDES WILLIAM R                          58           386335  \n",
       "HANNON KEVIN P                          1035           853064  \n",
       "...                                      ...              ...  \n",
       "GRAMM WENDY L                            NaN              NaN  \n",
       "CAUSEY RICHARD A                        1585          2502063  \n",
       "TAYLOR MITCHELL S                        300           563798  \n",
       "DONAHUE JR JEFFREY M                     772           315068  \n",
       "GLISAN JR BEN F                          874           393818  \n",
       "\n",
       "[144 rows x 17 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>salary</th>\n      <th>to_messages</th>\n      <th>total_payments</th>\n      <th>bonus</th>\n      <th>email_address</th>\n      <th>deferred_income</th>\n      <th>total_stock_value</th>\n      <th>expenses</th>\n      <th>from_poi_to_this_person</th>\n      <th>exercised_stock_options</th>\n      <th>from_messages</th>\n      <th>other</th>\n      <th>from_this_person_to_poi</th>\n      <th>poi</th>\n      <th>long_term_incentive</th>\n      <th>shared_receipt_with_poi</th>\n      <th>restricted_stock</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>METTS MARK</th>\n      <td>365788</td>\n      <td>807</td>\n      <td>1061827</td>\n      <td>600000</td>\n      <td>mark.metts@enron.com</td>\n      <td>NaN</td>\n      <td>585062</td>\n      <td>94299</td>\n      <td>38</td>\n      <td>NaN</td>\n      <td>29</td>\n      <td>1740</td>\n      <td>1</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>702</td>\n      <td>585062</td>\n    </tr>\n    <tr>\n      <th>BAXTER JOHN C</th>\n      <td>267102</td>\n      <td>NaN</td>\n      <td>5634343</td>\n      <td>1200000</td>\n      <td>NaN</td>\n      <td>-1386055</td>\n      <td>10623258</td>\n      <td>11200</td>\n      <td>NaN</td>\n      <td>6680544</td>\n      <td>NaN</td>\n      <td>2660303</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>1586055</td>\n      <td>NaN</td>\n      <td>3942714</td>\n    </tr>\n    <tr>\n      <th>ELLIOTT STEVEN</th>\n      <td>170941</td>\n      <td>NaN</td>\n      <td>211725</td>\n      <td>350000</td>\n      <td>steven.elliott@enron.com</td>\n      <td>-400729</td>\n      <td>6678735</td>\n      <td>78552</td>\n      <td>NaN</td>\n      <td>4890344</td>\n      <td>NaN</td>\n      <td>12961</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1788391</td>\n    </tr>\n    <tr>\n      <th>CORDES WILLIAM R</th>\n      <td>NaN</td>\n      <td>764</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>bill.cordes@enron.com</td>\n      <td>NaN</td>\n      <td>1038185</td>\n      <td>NaN</td>\n      <td>10</td>\n      <td>651850</td>\n      <td>12</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>58</td>\n      <td>386335</td>\n    </tr>\n    <tr>\n      <th>HANNON KEVIN P</th>\n      <td>243293</td>\n      <td>1045</td>\n      <td>288682</td>\n      <td>1500000</td>\n      <td>kevin.hannon@enron.com</td>\n      <td>-3117011</td>\n      <td>6391065</td>\n      <td>34039</td>\n      <td>32</td>\n      <td>5538001</td>\n      <td>32</td>\n      <td>11350</td>\n      <td>21</td>\n      <td>True</td>\n      <td>1617011</td>\n      <td>1035</td>\n      <td>853064</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>GRAMM WENDY L</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>119292</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>CAUSEY RICHARD A</th>\n      <td>415189</td>\n      <td>1892</td>\n      <td>1868758</td>\n      <td>1000000</td>\n      <td>richard.causey@enron.com</td>\n      <td>-235000</td>\n      <td>2502063</td>\n      <td>30674</td>\n      <td>58</td>\n      <td>NaN</td>\n      <td>49</td>\n      <td>307895</td>\n      <td>12</td>\n      <td>True</td>\n      <td>350000</td>\n      <td>1585</td>\n      <td>2502063</td>\n    </tr>\n    <tr>\n      <th>TAYLOR MITCHELL S</th>\n      <td>265214</td>\n      <td>533</td>\n      <td>1092663</td>\n      <td>600000</td>\n      <td>mitchell.taylor@enron.com</td>\n      <td>NaN</td>\n      <td>3745048</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>3181250</td>\n      <td>29</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>300</td>\n      <td>563798</td>\n    </tr>\n    <tr>\n      <th>DONAHUE JR JEFFREY M</th>\n      <td>278601</td>\n      <td>865</td>\n      <td>875760</td>\n      <td>800000</td>\n      <td>jeff.donahue@enron.com</td>\n      <td>-300000</td>\n      <td>1080988</td>\n      <td>96268</td>\n      <td>188</td>\n      <td>765920</td>\n      <td>22</td>\n      <td>891</td>\n      <td>11</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>772</td>\n      <td>315068</td>\n    </tr>\n    <tr>\n      <th>GLISAN JR BEN F</th>\n      <td>274975</td>\n      <td>873</td>\n      <td>1272284</td>\n      <td>600000</td>\n      <td>ben.glisan@enron.com</td>\n      <td>NaN</td>\n      <td>778546</td>\n      <td>125978</td>\n      <td>52</td>\n      <td>384728</td>\n      <td>16</td>\n      <td>200308</td>\n      <td>6</td>\n      <td>True</td>\n      <td>71023</td>\n      <td>874</td>\n      <td>393818</td>\n    </tr>\n  </tbody>\n</table>\n<p>144 rows × 17 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "enron_df = (pd.DataFrame.from_dict(data_dict)).T\n",
    "enron_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nDirectory \"../output\" already exists - nothing done.\n\nWriting data set to ../../output/enron_data.csv\n"
     ]
    }
   ],
   "source": [
    "#--- create dataframe from updated dictionary dataset:\n",
    "convert_to_csv(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'to_numeric'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-14cde7c6d4e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#--- Explore money features:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0menron_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0msalary_avg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menron_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'poi'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'salary'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboxplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'poi'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'salary'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menron_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nano_p4/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5463\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5464\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5465\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5467\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'to_numeric'"
     ]
    }
   ],
   "source": [
    "#--- further explore the new dataset by looking into each feature:\n",
    "\n",
    "#--- Money related features:\n",
    "money_features = ['salary', 'total_payments', 'bonus', 'deferred_income', 'total_stock_value', \n",
    "    'expenses', 'exercised_stock_options', 'long_term_incentive', 'restricted_stock']\n",
    "#--- Email related features:\n",
    "email_features = ['email_address', 'from_poi_to_this_person','from_this_person_to_poi','from_messages',\n",
    "    'shared_receipt_with_poi','to_messages']\n",
    "\n",
    "#--- Explore money features:\n",
    "enron_df.to_numeric()\n",
    "salary_avg = enron_df.groupby('poi').mean()['salary']\n",
    "sns.boxplot(x='poi', y='salary', data = enron_df)\n",
    "\n",
    "#--- Compare POI data vs non-POI data:"
   ]
  },
  {
   "source": [
    "<h3>Ratio of NaN entries per feature in dataset:</h3>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<h2>Question 2</h2>\n",
    "\n",
    ">\n",
    "What features did you end up using in your POI identifier, and what selection process did you use to pick them? Did you have to do any scaling? Why or why not? As part of the assignment, you should attempt to engineer your own feature that does not come ready-made in the dataset -- explain what feature you tried to make, and the rationale behind it. (You do not necessarily have to use it in the final analysis, only engineer and test it.) In your feature selection step, if you used an algorithm like a decision tree, please also give the feature importance of the features that you use, and if you used an automated feature selection function like SelectKBest, please report the feature scores and reasons for your choice of parameter values. [relevant rubric items: “create new features”, “intelligently select features”, “properly scale features”]"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}